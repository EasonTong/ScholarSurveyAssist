{"data": [{"arxiv": {"page": "https://arxiv.org/abs/2202.07371", "id": "2202.07371", "pdf": "https://arxiv.org/pdf/2202.07371", "other": "https://arxiv.org/format/2202.07371"}, "title": "Personalized Prompt Learning for Explainable Recommendation", "author_info": ["Lei Li", "Yongfeng Zhang", "Li Chen"], "summary": "Providing user-understandable explanations to justify recommendations could help users better understand the recommended items, increase the system's ease of use, and gain users' trust. A typical approach to realize it is natural language generation. However, previous works mostly adopt recurrent neural networks to meet the ends, leaving the potentially more effective pre-trained Transformer models under-explored. In fact, user and item IDs, as important identifiers in recommender systems, are inherently in different semantic space as words that pre-trained models were already trained on. Thus, how to effectively fuse IDs into such models becomes a critical issue. Inspired by recent advancement in prompt learning, we come up with two solutions: find alternative words to represent IDs (called discrete prompt learning), and directly input ID vectors to a pre-trained model (termed continuous prompt learning). In the latter case, ID vectors are randomly initialized but the model is trained in advance on large corpora, so they are actually in different learning stages. To bridge the gap, we further propose two training strategies: sequential tuning and recommendation as regularization. Extensive experiments show that our continuous prompt learning approach equipped with the training strategies consistently outperforms strong baselines on three datasets of explainable recommendation.", "comment": ""}, {"arxiv": {"page": "https://arxiv.org/abs/2202.07255", "id": "2202.07255", "pdf": "https://arxiv.org/pdf/2202.07255", "other": "https://arxiv.org/format/2202.07255"}, "title": "Enhancing Cross-lingual Prompting with Mask Token Augmentation", "author_info": ["Meng Zhou", "Xin Li", "Yue Jiang", "Lidong Bing"], "summary": "Prompting shows promising results in few-shot scenarios. However, its strength for multilingual/cross-lingual problems has not been fully exploited. Zhao and Sch\u00fctze (2021) made initial explorations in this direction by presenting that cross-lingual prompting outperforms cross-lingual finetuning. In this paper, we conduct empirical analysis on the effect of each component in cross-lingual prompting and derive Universal Prompting across languages, which helps alleviate the discrepancies between source-language training and target-language inference. Based on this, we propose a mask token augmentation framework to further improve the performance of prompt-based cross-lingual transfer. Notably, for XNLI, our method achieves 46.54% with only 16 English training examples per class, significantly better than 34.99% of finetuning.", "comment": ""}, {"arxiv": {"page": "https://arxiv.org/abs/2202.06687", "id": "2202.06687", "pdf": "https://arxiv.org/pdf/2202.06687", "other": "https://arxiv.org/format/2202.06687"}, "title": "Domain Adaptation via Prompt Learning", "author_info": ["Chunjiang Ge", "Rui Huang", "Mixue Xie", "Zihang Lai", "Shiji Song", "Shuang Li", "Gao Huang"], "summary": "Unsupervised domain adaption (UDA) aims to adapt models learned from a well-annotated source domain to a target domain, where only unlabeled samples are given. Current UDA approaches learn domain-invariant features by aligning source and target feature spaces. Such alignments are imposed by constraints such as statistical discrepancy minimization or adversarial training. However, these constraints could lead to the distortion of semantic feature structures and loss of class discriminability. In this paper, we introduce a novel prompt learning paradigm for UDA, named Domain Adaptation via Prompt Learning (DAPL). In contrast to prior works, our approach makes use of pre-trained vision-language models and optimizes only very few parameters. The main idea is to embed domain information into prompts, a form of representations generated from natural language, which is then used to perform classification. This domain information is shared only by images from the same domain, thereby dynamically adapting the classifier according to each domain. By adopting this paradigm, we show that our model not only outperforms previous methods on several cross-domain benchmarks but also is very efficient to train and easy to implement.", "comment": " Comments: 10 pages, 5 figures "}, {"arxiv": {"page": "https://arxiv.org/abs/2202.04824", "id": "2202.04824", "pdf": "https://arxiv.org/pdf/2202.04824", "other": "https://arxiv.org/format/2202.04824"}, "title": "AdaPrompt: Adaptive Model Training for Prompt-based NLP", "author_info": ["Yulong Chen", "Yang Liu", "Li Dong", "Shuohang Wang", "Chenguang Zhu", "Michael Zeng", "Yue Zhang"], "summary": "Prompt-based learning, with its capability to tackle zero-shot and few-shot NLP tasks, has gained much attention in community. The main idea is to bridge the gap between NLP downstream tasks and language modeling (LM), by mapping these tasks into natural language prompts, which are then filled by pre-trained language models (PLMs). However, for prompt learning, there are still two salient gaps between NLP tasks and pretraining. First, prompt information is not necessarily sufficiently present during LM pretraining. Second, task-specific data are not necessarily well represented during pretraining. We address these two issues by proposing AdaPrompt, adaptively retrieving external data for continual pretraining of PLMs by making use of both task and prompt characteristics. In addition, we make use of knowledge in Natural Language Inference models for deriving adaptive verbalizers. Experimental results on five NLP benchmarks show that AdaPrompt can improve over standard PLMs in few-shot settings. In addition, in zero-shot settings, our method outperforms standard prompt-based methods by up to 26.35\\% relative error reduction.", "comment": ""}, {"arxiv": {"page": "https://arxiv.org/abs/2202.02944", "id": "2202.02944", "pdf": "https://arxiv.org/pdf/2202.02944", "other": "https://arxiv.org/format/2202.02944"}, "title": "Prompt-Guided Injection of Conformation to Pre-trained Protein Model", "author_info": ["Qiang Zhang", "Zeyuan Wang", "Yuqiang Han", "Haoran Yu", "Xurui Jin", "Huajun Chen"], "summary": "Pre-trained protein models (PTPMs) represent a protein with one fixed embedding and thus are not capable for diverse tasks. For example, protein structures can shift, namely protein folding, between several conformations in various biological processes. To enable PTPMs to produce task-aware representations, we propose to learn interpretable, pluggable and extensible protein prompts as a way of injecting task-related knowledge into PTPMs. In this regard, prior PTPM optimization with the masked language modeling task can be interpreted as learning a sequence prompt (Seq prompt) that enables PTPMs to capture the sequential dependency between amino acids. To incorporate conformational knowledge to PTPMs, we propose an interaction-conformation prompt (IC prompt) that is learned through back-propagation with the protein-protein interaction task. As an instantiation, we present a conformation-aware pre-trained protein model that learns both sequence and interaction-conformation prompts in a multi-task setting. We conduct comprehensive experiments on nine protein datasets. Results confirm our expectation that using the sequence prompt does not hurt PTPMs' performance on sequence-related tasks while incorporating the interaction-conformation prompt significantly improves PTPMs' performance on tasks where conformational knowledge counts. We also show the learned prompts can be combined and extended to deal with new complex tasks.", "comment": " Comments: Work in progress "}, {"arxiv": {"page": "https://arxiv.org/abs/2202.01279", "id": "2202.01279", "pdf": "https://arxiv.org/pdf/2202.01279", "other": "https://arxiv.org/format/2202.01279"}, "title": "PromptSource: An Integrated Development Environment and Repository for Natural Language Prompts", "author_info": ["Stephen H. Bach", "Victor Sanh", "Zheng-Xin Yong", "Albert Webson", "Colin Raffel", "Nihal V. Nayak", "Abheesht Sharma", "Taewoon Kim", "M Saiful Bari", "Thibault Fevry", "Zaid Alyafeai", "Manan Dey", "Andrea Santilli", "Zhiqing Sun", "Srulik Ben-David", "Canwen Xu", "Gunjan Chhablani", "Han Wang", "Jason Alan Fries", "Maged S. Al-shaibani", "Shanya Sharma", "Urmish Thakker", "Khalid Almubarak", "Xiangru Tang", "Xiangru Tang"], "summary": "PromptSource is a system for creating, sharing, and using natural language prompts. Prompts are functions that map an example from a dataset to a natural language input and target output. Using prompts to train and query language models is an emerging area in NLP that requires new tools that let users develop and refine these prompts collaboratively. PromptSource addresses the emergent challenges in this new setting with (1) a templating language for defining data-linked prompts, (2) an interface that lets users quickly iterate on prompt development by observing outputs of their prompts on many examples, and (3) a community-driven set of guidelines for contributing new prompts to a common pool. Over 2,000 prompts for roughly 170 datasets are already available in PromptSource. PromptSource is available at https://github.com/bigscience-workshop/promptsource.", "comment": ""}, {"arxiv": {"page": "https://arxiv.org/abs/2202.00828", "id": "2202.00828", "pdf": "https://arxiv.org/pdf/2202.00828", "other": "https://arxiv.org/format/2202.00828"}, "title": "Co-training Improves Prompt-based Learning for Large Language Models", "author_info": ["Hunter Lang", "Monica Agrawal", "Yoon Kim", "David Sontag"], "summary": "We demonstrate that co-training (Blum & Mitchell, 1998) can improve the performance of prompt-based learning by using unlabeled data. While prompting has emerged as a promising paradigm for few-shot and zero-shot learning, it is often brittle and requires much larger models compared to the standard supervised setup. We find that co-training makes it possible to improve the original prompt model and at the same time learn a smaller, downstream task-specific model. In the case where we only have partial access to a prompt model (e.g., output probabilities from GPT-3 (Brown et al., 2020)) we learn a calibration model over the prompt outputs. When we have full access to the prompt model's gradients but full finetuning remains prohibitively expensive (e.g., T0 (Sanh et al., 2021)), we learn a set of soft prompt continuous vectors to iteratively update the prompt model. We find that models trained in this manner can significantly improve performance on challenging datasets where there is currently a large gap between prompt-based learning and fully-supervised models.", "comment": " Comments: 17 pages, 8 figures "}, {"arxiv": {"page": "https://arxiv.org/abs/2202.00815", "id": "2202.00815", "pdf": "https://arxiv.org/pdf/2202.00815", "other": "https://arxiv.org/format/2202.00815"}, "title": "Measurement of beauty production via non-prompt D0 mesons in Pb-Pb collisions at sNN\u2212\u2212\u2212\u221a = 5.02 TeV", "author_info": [" ALICE Collaboration"], "summary": "The production of non-prompt D0 mesons from beauty-hadron decays was measured at midrapidity (|y|<0.5) in Pb-Pb collisions at a nucleon-nucleon center-of-mass energy of sNN\u2212\u2212\u2212\u221a=5.02\u00a0TeV with the ALICE experiment at the LHC. Their nuclear modification factor (RAA), measured for the first time down to pT=1\u00a0GeV/c in the 0\u221210% and 30\u221250% centrality classes, indicates a significant suppression, up to a factor of about three, for pT>5\u00a0GeV/c in the 0\u221210% central Pb-Pb collisions. The data are described by models that include both collisional and radiative processes in the calculation of beauty-quark energy loss in the quark-gluon plasma, and quark recombination in addition to fragmentation as a hadronization mechanism. The ratio of the non-prompt to prompt D0-meson RAA is larger than unity for pT>4\u00a0GeV/c in the 0\u221210% central Pb-Pb collisions, as predicted by models in which beauty quarks lose less energy than charm quarks in the quark-gluon plasma because of their larger mass.", "comment": " Report number:           CERN-EP-2022-015                                    "}, {"arxiv": {"page": "https://arxiv.org/abs/2202.00535", "id": "2202.00535", "pdf": "https://arxiv.org/pdf/2202.00535", "other": "https://arxiv.org/format/2202.00535"}, "title": "Novelty Controlled Paraphrase Generation with Retrieval Augmented Conditional Prompt Tuning", "author_info": ["Jishnu Ray Chowdhury", "Yong Zhuang", "Shuyi Wang"], "summary": "Paraphrase generation is a fundamental and long-standing task in natural language processing. In this paper, we concentrate on two contributions to the task: (1) we propose Retrieval Augmented Prompt Tuning (RAPT) as a parameter-efficient method to adapt large pre-trained language models for paraphrase generation; (2) we propose Novelty Conditioned RAPT (NC-RAPT) as a simple model-agnostic method of using specialized prompt tokens for controlled paraphrase generation with varying levels of lexical novelty. By conducting extensive experiments on four datasets, we demonstrate the effectiveness of the proposed approaches for retaining the semantic content of the original text while inducing lexical novelty in the generation.", "comment": " Comments: Accepted by AAAI 2022 "}, {"arxiv": {"page": "https://arxiv.org/abs/2201.12109", "id": "2201.12109", "pdf": "https://arxiv.org/pdf/2201.12109", "other": "https://arxiv.org/format/2201.12109"}, "title": "Protum: A New Method For Prompt Tuning Based on \"[MASK]\"", "author_info": ["Pan He", "Yuxi Chen", "Yan Wang", "Yanru Zhang"], "summary": "Recently, prompt tuning \\cite{lester2021power} has gradually become a new paradigm for NLP, which only depends on the representation of the words by freezing the parameters of pre-trained language models (PLMs) to obtain remarkable performance on downstream tasks. It maintains the consistency of Masked Language Model (MLM) \\cite{devlin2018bert} task in the process of pre-training, and avoids some issues that may happened during fine-tuning. Naturally, we consider that the \"[MASK]\" tokens carry more useful information than other tokens because the model combines with context to predict the masked tokens. Among the current prompt tuning methods, there will be a serious problem of random composition of the answer tokens in prediction when they predict multiple words so that they have to map tokens to labels with the help verbalizer. In response to the above issue, we propose a new \\textbf{Pro}mpt \\textbf{Tu}ning based on \"[\\textbf{M}ASK]\" (\\textbf{Protum}) method in this paper, which constructs a classification task through the information carried by the hidden layer of \"[MASK]\" tokens and then predicts the labels directly rather than the answer tokens. At the same time, we explore how different hidden layers under \"[MASK]\" impact on our classification model on many different data sets. Finally, we find that our \\textbf{Protum} can achieve much better performance than fine-tuning after continuous pre-training with less time consumption. Our model facilitates the practical application of large models in NLP.", "comment": " Comments: under review in ICML "}, {"arxiv": {"page": "https://arxiv.org/abs/2201.11903", "id": "2201.11903", "pdf": "https://arxiv.org/pdf/2201.11903", "other": "https://arxiv.org/format/2201.11903"}, "title": "Chain of Thought Prompting Elicits Reasoning in Large Language Models", "author_info": ["Jason Wei", "Xuezhi Wang", "Dale Schuurmans", "Maarten Bosma", "Ed Chi", "Quoc Le", "Denny Zhou"], "summary": "Although scaling up language model size has reliably improved performance on a range of NLP tasks, even the largest models currently struggle with certain reasoning tasks such as math word problems, symbolic manipulation, and commonsense reasoning. This paper explores the ability of language models to generate a coherent chain of thought -- a series of short sentences that mimic the reasoning process a person might have when responding to a question. Experiments show that inducing a chain of thought via prompting can enable sufficiently large language models to better perform reasoning tasks that otherwise have flat scaling curves.", "comment": ""}, {"arxiv": {"page": "https://arxiv.org/abs/2201.11332", "id": "2201.11332", "pdf": "https://arxiv.org/pdf/2201.11332", "other": "https://arxiv.org/format/2201.11332"}, "title": "Ontology-enhanced Prompt-tuning for Few-shot Learning", "author_info": ["Hongbin Ye", "Ningyu Zhang", "Shumin Deng", "Xiang Chen", "Hui Chen", "Feiyu Xiong", "Xi Chen", "Huajun Chen"], "summary": "Few-shot Learning (FSL) is aimed to make predictions based on a limited number of samples. Structured data such as knowledge graphs and ontology libraries has been leveraged to benefit the few-shot setting in various tasks. However, the priors adopted by the existing methods suffer from challenging knowledge missing, knowledge noise, and knowledge heterogeneity, which hinder the performance for few-shot learning. In this study, we explore knowledge injection for FSL with pre-trained language models and propose ontology-enhanced prompt-tuning (OntoPrompt). Specifically, we develop the ontology transformation based on the external knowledge graph to address the knowledge missing issue, which fulfills and converts structure knowledge to text. We further introduce span-sensitive knowledge injection via a visible matrix to select informative knowledge to handle the knowledge noise issue. To bridge the gap between knowledge and text, we propose a collective training algorithm to optimize representations jointly. We evaluate our proposed OntoPrompt in three tasks, including relation extraction, event extraction, and knowledge graph completion, with eight datasets. Experimental results demonstrate that our approach can obtain better few-shot performance than baselines.", "comment": " Comments: Accepted by WWW2022 "}, {"arxiv": {"page": "https://arxiv.org/abs/2201.10963", "id": "2201.10963", "pdf": "https://arxiv.org/pdf/2201.10963", "other": "https://arxiv.org/format/2201.10963"}, "title": "Learning to Compose Diversified Prompts for Image Emotion Classification", "author_info": ["Sinuo Deng", "Lifang Wu", "Ge Shi", "Lehao Xing", "Meng Jian"], "summary": "Contrastive Language-Image Pre-training (CLIP) represents the latest incarnation of pre-trained vision-language models. Although CLIP has recently shown its superior power on a wide range of downstream vision-language tasks like Visual Question Answering, it is still underexplored for Image Emotion Classification (IEC). Adapting CLIP to the IEC task has three significant challenges, tremendous training objective gap between pretraining and IEC, shared suboptimal and invariant prompts for all instances. In this paper, we propose a general framework that shows how CLIP can be effectively applied to IEC. We first introduce a prompt tuning method that mimics the pretraining objective of CLIP and thus can leverage the rich image and text semantics entailed in CLIP. Then we automatically compose instance-specific prompts by conditioning them on the categories and image contents of instances, diversifying prompts and avoiding suboptimal problems. Evaluations on six widely-used affective datasets demonstrate that our proposed method outperforms the state-of-the-art methods to a large margin (i.e., up to 9.29% accuracy gain on EmotionROI dataset) on IEC tasks, with only a few parameters trained. Our codes will be publicly available for research purposes.", "comment": " Comments: 7 pages, 3 figures "}, {"arxiv": {"page": "https://arxiv.org/abs/2201.08670", "id": "2201.08670", "pdf": "https://arxiv.org/pdf/2201.08670", "other": "https://arxiv.org/format/2201.08670"}, "title": "Context-Tuning: Learning Contextualized Prompts for Natural Language Generation", "author_info": ["Tianyi Tang", "Junyi Li", "Wayne Xin Zhao"], "summary": "Recently, pretrained language models (PLMs) have made exceptional success in language generation. To leverage the rich knowledge encoded by PLMs, a simple yet powerful mechanism is to use prompts, in the form of either discrete tokens or continuous embeddings. In existing studies, manual prompts are time-consuming and require domain expertise, while continuous prompts are typically independent of the inputs. To address this issue, we propose a novel continuous prompting approach, called Context-Tuning, to fine-tuning PLMs for natural language generation. Firstly, the prompts are derived based on the input text, so that they can elicit useful knowledge from PLMs for generation. We refer to such prompts as contextualized prompts. Secondly, to further enhance the relevance of the generated text to the inputs, we utilize continuous inverse prompting to refine the process of natural language generation by modeling an inverse generation process from output to input. Moreover, we propose a lightweight contexttuning, fine-tuning only 0.4% of parameters while retaining well performance.", "comment": " Comments: 13 pages, 6 figures, 6 tables "}, {"arxiv": {"page": "https://arxiv.org/abs/2201.08531", "id": "2201.08531", "pdf": "https://arxiv.org/pdf/2201.08531", "other": "https://arxiv.org/format/2201.08531"}, "title": "Black-box Prompt Learning for Pre-trained Language Models", "author_info": ["Shizhe Diao", "Xuechun Li", "Yong Lin", "Zhichao Huang", "Tong Zhang"], "summary": "Domain-specific fine-tuning strategies for large pre-trained models received vast attention in recent years. In previously studied settings, the model architectures and parameters are tunable or at least visible, which we refer to as white-box settings. This work considers a new scenario, where we do not have access to a pre-trained model, except for its outputs given inputs, and we call this problem black-box fine-tuning. To illustrate our approach, we first introduce the black-box setting formally on text classification, where the pre-trained model is not only frozen but also invisible. We then propose our solution black-box prompt, a new technique in the prompt-learning family, which can leverage the knowledge learned by pre-trained models from the pre-training corpus. Our experiments demonstrate that the proposed method achieved the state-of-the-art performance on eight datasets. Further analyses on different human-designed objectives, prompt lengths, and intuitive explanations demonstrate the robustness and flexibility of our method.", "comment": " Comments: 10 pages, 5 figures "}, {"arxiv": {"page": "https://arxiv.org/abs/2201.07916", "id": "2201.07916", "pdf": "https://arxiv.org/pdf/2201.07916", "other": "https://arxiv.org/format/2201.07916"}, "title": "PROMPT: Learning Dynamic Resource Allocation Policies for Edge-Network Applications", "author_info": ["Drew Penney", "Bin Li", "Jaroslaw Sydir", "Charlie Tai", "Eoin Walsh", "Thomas Long", "Stefan Lee", "Lizhong Chen"], "summary": "A growing number of service providers are exploring methods to improve server utilization, reduce power consumption, and reduce total cost of ownership by co-scheduling high-priority latency-critical workloads with best-effort workloads. This practice requires strict resource allocation between workloads to reduce resource contention and maintain Quality of Service (QoS) guarantees. Prior resource allocation works have been shown to improve server utilization under ideal circumstances, yet often compromise QoS guarantees or fail to find valid resource allocations in more dynamic operating environments. Further, prior works are fundamentally reliant upon QoS measurements that can, in practice, exhibit significant transient fluctuations, thus stable control behavior cannot be reliably achieved. In this paper, we propose a novel framework for dynamic resource allocation based on proactive QoS prediction. These predictions help guide a reinforcement-learning-based resource controller towards optimal resource allocations while avoiding transient QoS violations due to fluctuating workload demands. Evaluation shows that the proposed method incurs 4.3x fewer QoS violations, reduces severity of QoS violations by 3.7x, improves best-effort workload performance, and improves overall power efficiency compared with prior work.", "comment": ""}, {"arxiv": {"page": "https://arxiv.org/abs/2201.07126", "id": "2201.07126", "pdf": "https://arxiv.org/pdf/2201.07126", "other": "https://arxiv.org/format/2201.07126"}, "title": "Instance-aware Prompt Learning for Language Understanding and Generation", "author_info": ["Feihu Jin", "Jinliang Lu", "Jiajun Zhang", "Chengqing Zong"], "summary": "Recently, prompt learning has become a new paradigm to utilize pre-trained language models (PLMs) and achieves promising results in downstream tasks with a negligible increase of parameters. The current usage of discrete and continuous prompts assumes that the prompt is fixed for a specific task and all samples in the task share the same prompt. However, a task may contain quite diverse samples in which some are easy and others are difficult, and diverse prompts are desirable. In this paper, we propose an instance-aware prompt learning method that learns a different prompt for each instance. Specifically, we suppose that each learnable prompt token has a different contribution to different instances, and we learn the contribution by calculating the relevance score between an instance and each prompt token. The contribution weighted prompt would be instance aware. We apply our method to both unidirectional and bidirectional PLMs on both language understanding and generation tasks. Extensive experiments demonstrate that our method obtains considerable improvements compared to strong baselines. Especially, our method achieves the state-of-the-art on the SuperGLUE few-shot learning benchmark.", "comment": " Comments: 7 pages, 5 figures "}, {"arxiv": {"page": "https://arxiv.org/abs/2201.07099", "id": "2201.07099", "pdf": "https://arxiv.org/pdf/2201.07099", "other": "https://arxiv.org/format/2201.07099"}, "title": "Inferring Commonsense Explanations as Prompts for Future Event Generation", "author_info": ["Li Lin", "Yixin Cao", "Lifu Huang", "Shuang Li", "Xuming Hu", "Lijie Wen", "Jianmin Wang"], "summary": "Future Event Generation aims to generate fluent and reasonable future event descriptions given preceding events. It requires not only fluent text generation but also commonsense reasoning to maintain the coherence of the entire event story. However, existing FEG methods are easily trapped into repeated or general events without imposing any logical constraint to the generation process. In this paper, we propose a novel explainable FEG framework that consists of a commonsense inference model (IM) and an event generation model (GM). The IM, which is pre-trained on a commonsense knowledge graph ATOMIC, learns to interpret the preceding events and conducts commonsense reasoning to reveal the characters psychology such as intent, reaction, and needs as latent variables. GM further takes the commonsense knowledge as prompts to guide and enforce the generation of logistically coherent future events. As unique merit, the commonsense prompts can be further decoded into textual descriptions, yielding explanations for the future event. Automatic and human evaluation demonstrate that our approach can generate more coherent, specific, and logical future events than the strong baselines.", "comment": " ACM Class:           I.2.7; I.2.4                "}, {"arxiv": {"page": "https://arxiv.org/abs/2201.06910", "id": "2201.06910", "pdf": "https://arxiv.org/pdf/2201.06910", "other": "https://arxiv.org/format/2201.06910"}, "title": "ZeroPrompt: Scaling Prompt-Based Pretraining to 1,000 Tasks Improves Zero-Shot Generalization", "author_info": ["Hanwei Xu", "Yujun Chen", "Yulun Du", "Nan Shao", "Yanggang Wang", "Haiyu Li", "Zhilin Yang"], "summary": "We propose a multitask pretraining approach ZeroPrompt for zero-shot generalization, focusing on task scaling and zero-shot prompting. While previous models are trained on only a few dozen tasks, we scale to 1,000 tasks for the first time using real-world data. This leads to a crucial discovery that task scaling can be an efficient alternative to model scaling; i.e., the model size has little impact on performance with an extremely large number of tasks. Our results show that task scaling can substantially improve training efficiency by 30 times in FLOPs. Moreover, we present a prompting method that incorporates a genetic algorithm to automatically search for the best prompt for unseen tasks, along with a few other improvements. Empirically, ZeroPrompt substantially improves both the efficiency and the performance of zero-shot learning across a variety of academic and production datasets.", "comment": " Comments: 23 pages "}, {"arxiv": {"page": "https://arxiv.org/abs/2201.06481", "id": "2201.06481", "pdf": "https://arxiv.org/pdf/2201.06481", "other": "https://arxiv.org/format/2201.06481"}, "title": "Investigation of the Prompt SNe Ia progenitor nature through the analysis of the chemical composition of globular clusters and circumgalactic clouds", "author_info": ["Irina A. Acharova", "Margarita E. Sharina", "Egor A. Kazakov"], "summary": "A method is proposed for determining the properties of type Ia supernovae from short-lived precursors -- Prompt SNIa. This method is based on the assumption that this subtype of type Ia supernovae exploded into low-metallicity globular clusters (GCs), and is responsible for the enrichment of the high-metallicity subgroup of GCs and circumgalactic clouds (CGCs) with the iron peak elements. We justify that CGCs are the formation places of GCs of both subgroups. The accuracy of the method depends, first, on the number of GCs, the spectra of which have been studied in detail; second, on the number of chemical elements, the abundances of which have been worked out. Only those elements are of interest for this method that are produced in supernova explosions and are not produced at the previous stage of the stellar evolution. Our estimates of nucleosynthesis in low-metallicity supernova GCs are in the best agreement with the following Prompt SNIa model: Single Degenerate Pure Deflagration Models of white dwarfs (WDs) burning with masses in the range from 1.30 Msun to 1.31 Msun if carbon explodes in the centre of a WD with a low central density from 0.5*10^9 g/cm^3 to 10^9 g/cm^3.", "comment": " Comments: 16 pages, 6 figures accepted for publication in Monthly Notices of the Royal Astronomical Society Main Journal "}, {"arxiv": {"page": "https://arxiv.org/abs/2201.06009", "id": "2201.06009", "pdf": "https://arxiv.org/pdf/2201.06009", "other": "https://arxiv.org/format/2201.06009"}, "title": "Memory-assisted prompt editing to improve GPT-3 after deployment", "author_info": ["Aman Madaan", "Niket Tandon", "Peter Clark", "Yiming Yang"], "summary": "Large LMs such as GPT-3, while powerful, are not immune to mistakes, but are prohibitively costly to retrain. One failure mode is misinterpreting a user's instruction (e.g., GPT-3 interpreting \"What word is similar to good?\" to mean a homonym, while the user intended a synonym). Our goal is to allow users to correct such errors directly through interaction -- without retraining. Our approach pairs GPT-3 with a growing memory of cases where the model misunderstood the user's intent and was provided with feedback, clarifying the instruction. Given a new query, our memory-enhanced GPT-3 uses feedback from similar, prior queries to enrich the prompt. Through simple proof-of-concept experiments, we show how a (simulated) user can interactively teach a deployed GPT-3, doubling its accuracy on basic lexical tasks (e.g., generate a synonym) where users query in different, novel (often misunderstood) ways. In such scenarios, memory helps avoid repeating similar past mistakes. Our simple idea is a first step towards strengthening deployed models, potentially broadening their utility. All the code and data is available at https://github.com/madaan/memprompt.", "comment": ""}, {"arxiv": {"page": "https://arxiv.org/abs/2201.05780", "id": "2201.05780", "pdf": "https://arxiv.org/pdf/2201.05780", "other": "https://arxiv.org/format/2201.05780"}, "title": "Prompt Learning for Few-Shot Dialogue State Tracking", "author_info": ["Yuting Yang", "Wenqiang Lei", "Juan Cao", "Jintao Li", "Tat-Seng Chua"], "summary": "Collecting dialogue state labels, slots and values, for learning dialogue state tracking (DST) models can be costly, especially with the wide application of dialogue systems in new-rising domains. In this paper, we focus on how to learn a DST model efficiently with limited labeled data. We design a prompt learning framework for few-shot DST, which consists of two main components: value-based prompt and inverse prompt mechanism. This framework aims to utilize the language understanding and generation ability of pre-trained language models (PLM). First, we design value-based prompt functions to probe the DST-related knowledge from PLM, which do not rely on the known ontology of slots. Further, an inverse prompt mechanism is utilized to self-check the \"prompted\" knowledge and help the PLM understand the essence of DST task further. Experiments show that our model can generate unseen slots and outperforms existing state-of-the-art few-shot methods. It indicates that DST-related knowledge can be probed from PLM and utilized to address low-resource DST efficiently with the help of prompt learning.", "comment": ""}, {"arxiv": {"page": "https://arxiv.org/abs/2201.05411", "id": "2201.05411", "pdf": "https://arxiv.org/pdf/2201.05411", "other": "https://arxiv.org/format/2201.05411"}, "title": "Eliciting Knowledge from Pretrained Language Models for Prototypical Prompt Verbalizer", "author_info": ["Yinyi Wei", "Tong Mo", "Yongtao Jiang", "Weiping Li", "Wen Zhao"], "summary": "Recent advances on prompt-tuning cast few-shot classification tasks as a masked language modeling problem. By wrapping input into a template and using a verbalizer which constructs a mapping between label space and label word space, prompt-tuning can achieve excellent results in zero-shot and few-shot scenarios. However, typical prompt-tuning needs a manually designed verbalizer which requires domain expertise and human efforts. And the insufficient label space may introduce considerable bias into the results. In this paper, we focus on eliciting knowledge from pretrained language models and propose a prototypical prompt verbalizer for prompt-tuning. Labels are represented by prototypical embeddings in the feature space rather than by discrete words. The distances between the embedding at the masked position of input and prototypical embeddings are used as classification criterion. For zero-shot settings, knowledge is elicited from pretrained language models by a manually designed template to form initial prototypical embeddings. For few-shot settings, models are tuned to learn meaningful and interpretable prototypical embeddings. Our method optimizes models by contrastive learning. Extensive experimental results on several many-class text classification datasets with low-resource settings demonstrate the effectiveness of our approach compared with other verbalizer construction methods. Our implementation is available at https://github.com/Ydongd/prototypical-prompt-verbalizer.", "comment": ""}, {"arxiv": {"page": "https://arxiv.org/abs/2201.04337", "id": "2201.04337", "pdf": "https://arxiv.org/pdf/2201.04337", "other": "https://arxiv.org/format/2201.04337"}, "title": "PromptBERT: Improving BERT Sentence Embeddings with Prompts", "author_info": ["Ting Jiang", "Shaohan Huang", "Zihan Zhang", "Deqing Wang", "Fuzhen Zhuang", "Furu Wei", "Haizhen Huang", "Liangjie Zhang", "Qi Zhang"], "summary": "The poor performance of the original BERT for sentence semantic similarity has been widely discussed in previous works. We find that unsatisfactory performance is mainly due to the static token embeddings biases and the ineffective BERT layers, rather than the high cosine similarity of the sentence embeddings. To this end, we propose a prompt based sentence embeddings method which can reduce token embeddings biases and make the original BERT layers more effective. By reformulating the sentence embeddings task as the fillin-the-blanks problem, our method significantly improves the performance of original BERT. We discuss two prompt representing methods and three prompt searching methods for prompt based sentence embeddings. Moreover, we propose a novel unsupervised training objective by the technology of template denoising, which substantially shortens the performance gap between the supervised and unsupervised setting. For experiments, we evaluate our method on both non fine-tuned and fine-tuned settings. Even a non fine-tuned method can outperform the fine-tuned methods like unsupervised ConSERT on STS tasks. Our fine-tuned method outperforms the state-of-the-art method SimCSE in both unsupervised and supervised settings. Compared to SimCSE, we achieve 2.29 and 2.58 points improvements on BERT and RoBERTa respectively under the unsupervised setting.", "comment": ""}, {"arxiv": {"page": "https://arxiv.org/abs/2201.03750", "id": "2201.03750", "pdf": "https://arxiv.org/pdf/2201.03750", "other": "https://arxiv.org/format/2201.03750"}, "title": "Gamma-ray Burst Prompt Emission Spectrum and Ep Evolution Patterns in the ICMART Model", "author_info": ["Xueying Shao", "He Gao"], "summary": "In this paper, we simulate the gamma-ray bursts (GRBs) prompt emission light curve, spectrum and Ep evolution patterns within the framework of the Internal-Collision-induced MAgnetic Reconnection and Turbulence (ICMART) model. We show that this model can produce a Band shape spectrum, whose parameters (Ep, \u03b1, \u03b2) could distribute in the typical distribution from GRB observations, as long as the magnetic field and the electron acceleration process in the emission region are under appropriate conditions. On the other hand, we show that for one ICMART event, Ep evolution is always a hard-to-soft pattern. However, a GRB light curve is usually composed of multiple ICMART events that are fundamentally driven by the erratic GRB central engine activity. In this case, we find that if one individual broad pulse in the GRB light curve is composed of multiple ICMART events, the overall Ep evolution could be disguised as the intense-tracking pattern. Therefore, mixed Ep evolution patterns can coexist in the same burst, with a variety of combined patterns. Our results support the ICMART model to be a competitive model to explain the main properties of GRB prompt emission. The possible challenges faced by the ICMART model are also discussed in details.", "comment": " Comments: Accepted for publication in ApJ "}, {"arxiv": {"page": "https://arxiv.org/abs/2201.00642", "id": "2201.00642", "pdf": "https://arxiv.org/pdf/2201.00642", "other": "https://arxiv.org/format/2201.00642"}, "title": "Detection of Prompt Fast-Variable Thermal Spectral Component in Multi-Pulse Short Gamma-Ray Burst 170206A", "author_info": ["Peng-Wei Zhao", "Qing-Wen Tang", "Yuan-Chuan Zou", "Kai Wang"], "summary": "We report the detection of strong thermal spectral component in the short Gamma-Ray Burst 170206A with three intensive pulses in its lightcurves, throughout which the fluxes of this thermal component exhibit fast temporal variability same as that of the accompanied non-thermal component. The values of the time-resolved low-energy photon index in the non-thermal component are between about -0.79 and -0.16, most of which are harder than the line-of-death (-2/3) of the synchrotron emission process. In addition, we found the plausible common evolution between the thermal component and the non-thermal component, Ep,CPL\u221dkTBB, and FCPL\u221dF2/3BB, where Ep,CPL and FCPL are the peak photon energy and corresponding flux of the non-thermal component, and kTBB and FBB are the temperature and corresponding flux of the thermal component, respectively. Finally, we explored the possible physical origins of GRB 170206A, suggesting the photospheric thermal emission and the Comptonization of thermal photons may be responsible for the observational features of GRB 170206A.", "comment": " Comments: 14 pages, 6 figures, revised version, comments are welcome "}, {"arxiv": {"page": "https://arxiv.org/abs/2112.14083", "id": "2112.14083", "pdf": "https://arxiv.org/pdf/2112.14083", "other": "https://arxiv.org/format/2112.14083"}, "title": "An energy independent scaling of transverse momentum spectra of direct (prompt) photons from two-body processes in high-energy proton-proton collisions", "author_info": ["Qiang Zhang", "Ya-Qin Gao", "Fu-Hu Liu", "Khusniddin K. Olimov"], "summary": "Transverse momentum spectra of direct (prompt) photons from two-body processes in high-energy proton-proton (p+p) collisions are analyzed in this paper. We collected the experimental invariant cross-sections at mid-rapidity in p+p collisions measured by the UA6, CCOR, R806, R110, PHENIX, NA24, CMS, ALICE, and ATLAS Collaborations over a center-of-mass energy range from 24.3 GeV to 13 TeV. In fitting the data, we used different kinds of functions which include the revised Tsallis--Pareto-type function (the TP-like function) at the particle level, the convolution of two TP-like functions at the quark level, and the root-sum-of-squares of two revised Tsallis-like functions in which the quark chemical potentials \u03bci=\u03bcB/3 or \u03bci=0, where \u03bcB is the baryon chemical potential. We have extracted the values of three main free parameters: the effective temperature T, power index n0 (or entropy index q), and correction index a0. After analyzing the changing trends of the parameters, we found that T, q, and a0 increase and n0 decreases with the increase of collision energy. Based on the analyses of transverse momentum spectra, an energy independent scaling, i.e. the xT scaling, is obtained.", "comment": " Comments: 25 pages, 10 figures, Annalen der Physik, accepted "}, {"arxiv": {"page": "https://arxiv.org/abs/2112.11851", "id": "2112.11851", "pdf": "https://arxiv.org/pdf/2112.11851", "other": "https://arxiv.org/format/2112.11851"}, "title": "Investigating the mass-ratio dependence of the prompt-collapse threshold with numerical-relativity simulations", "author_info": ["Maximilian K\u00f6lsch", "Tim Dietrich", "Maximiliano Ujevic", "Bernd Bruegmann"], "summary": "The next observing runs of advanced gravitational-wave detectors will lead to a variety of binary neutron star detections and numerous possibilities for multi-messenger observations of binary neutron star systems. In this context a clear understanding of the merger process and the possibility of prompt black hole formation after merger is important, as the amount of ejected material strongly depends on the merger dynamics. These dynamics are primarily affected by the total mass of the binary, however, the mass ratio also influences the postmerger evolution. To determine the effect of the mass ratio, we investigate the parameter space around the prompt-collapse threshold with a new set of fully relativistic simulations. The simulations cover three equations of state and seven mass ratios in the range of 1.0\u2264q\u22641.75, with five to seven simulations of binary systems of different total mass in each case. The threshold mass is determined through an empirical relation based on the collapse-time, which allows us to investigate effects of the mass-ratio on the threshold mass and also on the properties of the remnant system. Furthermore, we model effects of mass ratio and equation of state on tidal parameters of threshold configurations.", "comment": " Comments: 26 pages, 18 figures, 16 tables "}, {"arxiv": {"page": "https://arxiv.org/abs/2112.10833", "id": "2112.10833", "pdf": "https://arxiv.org/pdf/2112.10833", "other": "https://arxiv.org/format/2112.10833"}, "title": "Understanding User Perspectives on Prompts for Brief Reflection on Troubling Emotions", "author_info": ["Ananya Bhattacharjee", "Pan Chen", "Linjia Zhou", "Abhijoy Mandal", "Jai Aggarwal", "Katie O'Leary", "Anne Hsu", "Alex Mariakakis", "Joseph Jay Williams"], "summary": "We investigate users' perspectives on an online reflective question activity (RQA) that prompts people to externalize their underlying emotions on a troubling situation. Inspired by principles of cognitive behavioral therapy, our 15-minute activity encourages self-reflection without a human or automated conversational partner. A deployment of our RQA on Amazon Mechanical Turk suggests that people perceive several benefits from our RQA, including structured awareness of their thoughts and problem-solving around managing their emotions. Quantitative evidence from a randomized experiment suggests people find that our RQA makes them feel less worried by their selected situation and worth the minimal time investment. A further two-week technology probe deployment with 11 participants indicates that people see benefits to doing this activity repeatedly, although the activity may get monotonous over time. In summary, this work demonstrates the promise of online reflection activities that carefully leverage principles of psychology in their design.", "comment": " Comments: We investigate users' perspectives on an online reflective question activity (RQA) that prompts people to externalize their underlying emotions on a troubling situation "}, {"arxiv": {"page": "https://arxiv.org/abs/2112.10003", "id": "2112.10003", "pdf": "https://arxiv.org/pdf/2112.10003", "other": "https://arxiv.org/format/2112.10003"}, "title": "Prompt-Based Multi-Modal Image Segmentation", "author_info": ["Timo L\u00fcddecke", "Alexander S. Ecker"], "summary": "Image segmentation is usually addressed by training a model for a fixed set of object classes. Incorporating additional classes or more complex queries later is expensive as it requires re-training the model on a dataset that encompasses these expressions. Here we propose a system that can generate image segmentations based on arbitrary prompts at test time. A prompt can be either a text or an image. This approach enables us to create a unified model (trained once) for three common segmentation tasks, which come with distinct challenges: referring expression segmentation, zero-shot segmentation and one-shot segmentation. We build upon the CLIP model as a backbone which we extend with a transformer-based decoder that enables dense prediction. After training on an extended version of the PhraseCut dataset, our system generates a binary segmentation map for an image based on a free-text prompt or on an additional image expressing the query. Different variants of the latter image-based prompts are analyzed in detail. This novel hybrid input allows for dynamic adaptation not only to the three segmentation tasks mentioned above, but to any binary segmentation task where a text or image query can be formulated. Finally, we find our system to adapt well to generalized queries involving affordances or properties. Source code: https://eckerlab.org/code/clipseg", "comment": ""}, {"arxiv": {"page": "https://arxiv.org/abs/2112.09583", "id": "2112.09583", "pdf": "https://arxiv.org/pdf/2112.09583", "other": "https://arxiv.org/format/2112.09583"}, "title": "Align and Prompt: Video-and-Language Pre-training with Entity Prompts", "author_info": ["Dongxu Li", "Junnan Li", "Hongdong Li", "Juan Carlos Niebles", "Steven C. H. Hoi"], "summary": "Video-and-language pre-training has shown promising improvements on various downstream tasks. Most previous methods capture cross-modal interactions with a transformer-based multimodal encoder, not fully addressing the misalignment between unimodal video and text features. Besides, learning fine-grained visual-language alignment usually requires off-the-shelf object detectors to provide object information, which is bottlenecked by the detector's limited vocabulary and expensive computation cost.", "comment": ""}, {"arxiv": {"page": "https://arxiv.org/abs/2112.08718", "id": "2112.08718", "pdf": "https://arxiv.org/pdf/2112.08718", "other": "https://arxiv.org/format/2112.08718"}, "title": "Domain Prompts: Towards memory and compute efficient domain adaptation of ASR systems", "author_info": ["Saket Dingliwal", "Ashish Shenoy", "Sravan Bodapati", "Ankur Gandhe", "Ravi Teja Gadde", "Katrin Kirchhoff"], "summary": "Automatic Speech Recognition (ASR) systems have found their use in numerous industrial applications in very diverse domains. Since domain-specific systems perform better than their generic counterparts on in-domain evaluation, the need for memory and compute-efficient domain adaptation is obvious. Particularly, adapting parameter-heavy transformer-based language models used for rescoring ASR hypothesis is challenging. In this work, we introduce domain-prompts, a methodology that trains a small number of domain token embedding parameters to prime a transformer-based LM to a particular domain. With just a handful of extra parameters per domain, we achieve 7-14% WER improvement over the baseline of using an unadapted LM. Despite being parameter-efficient, these improvements are comparable to those of fully-fine-tuned models with hundreds of millions of parameters. With ablations on prompt-sizes, dataset sizes, initializations and domains, we provide evidence for the benefits of using domain-prompts in ASR systems.", "comment": " Comments: 4 pages ICASSP submission "}, {"arxiv": {"page": "https://arxiv.org/abs/2112.08654", "id": "2112.08654", "pdf": "https://arxiv.org/pdf/2112.08654", "other": "https://arxiv.org/format/2112.08654"}, "title": "Learning to Prompt for Continual Learning", "author_info": ["Zifeng Wang", "Zizhao Zhang", "Chen-Yu Lee", "Han Zhang", "Ruoxi Sun", "Xiaoqi Ren", "Guolong Su", "Vincent Perot", "Jennifer Dy", "Tomas Pfister"], "summary": "The mainstream paradigm behind continual learning has been to adapt the model parameters to non-stationary data distributions, where catastrophic forgetting is the central challenge. Typical methods rely on a rehearsal buffer or known task identity at test time to retrieve learned knowledge and address forgetting, while this work presents a new paradigm for continual learning that aims to train a more succinct memory system without accessing task identity at test time. Our method learns to dynamically prompt (L2P) a pre-trained model to learn tasks sequentially under different task transitions. In our proposed framework, prompts are small learnable parameters, which are maintained in a memory space. The objective is to optimize prompts to instruct the model prediction and explicitly manage task-invariant and task-specific knowledge while maintaining model plasticity. We conduct comprehensive experiments under popular image classification benchmarks with different challenging continual learning settings, where L2P consistently outperforms prior state-of-the-art methods. Surprisingly, L2P achieves competitive results against rehearsal-based methods even without a rehearsal buffer and is directly applicable to challenging task-agnostic continual learning. Source code is available at https://github.com/google-research/l2p.", "comment": ""}, {"arxiv": {"page": "https://arxiv.org/abs/2112.08633", "id": "2112.08633", "pdf": "https://arxiv.org/pdf/2112.08633", "other": "https://arxiv.org/format/2112.08633"}, "title": "Learning To Retrieve Prompts for In-Context Learning", "author_info": ["Ohad Rubin", "Jonathan Herzig", "Jonathan Berant"], "summary": "In-context learning is a recent paradigm in natural language understanding, where a large pre-trained language model (LM) observes a test instance and a few training examples as its input, and directly decodes the output without any update to its parameters. However, performance has been shown to strongly depend on the selected training examples (termed prompt). In this work, we propose an efficient method for retrieving prompts for in-context learning using annotated data and a LM. Given an input-output pair, we estimate the probability of the output given the input and a candidate training example as the prompt, and label training examples as positive or negative based on this probability. We then train an efficient dense retriever from this data, which is used to retrieve training examples as prompts at test time. We evaluate our approach on three sequence-to-sequence tasks where language utterances are mapped to meaning representations, and find that it substantially outperforms prior work and multiple baselines across the board.", "comment": ""}, {"arxiv": {"page": "https://arxiv.org/abs/2112.08348", "id": "2112.08348", "pdf": "https://arxiv.org/pdf/2112.08348", "other": "https://arxiv.org/format/2112.08348"}, "title": "PROMPT WAYWARDNESS: The Curious Case of Discretized Interpretation of Continuous Prompts", "author_info": ["Daniel Khashabi", "Shane Lyu", "Sewon Min", "Lianhui Qin", "Kyle Richardson", "Sameer Singh", "Sean Welleck", "Hannaneh Hajishirzi", "Tushar Khot", "Ashish Sabharwal", "Yejin Choi"], "summary": "Fine-tuning continuous prompts for target tasks has recently emerged as a compact alternative to full model fine-tuning. Motivated by these promising results, we investigate the feasibility of extracting a discrete (textual) interpretation of continuous prompts that is faithful to the problem they solve. In practice, we observe a \"wayward\" behavior between the task solved by continuous prompts and their nearest neighbor discrete projections: We can find continuous prompts that solve a task while being projected to an arbitrary text (e.g., definition of a different or even a contradictory task), while being within a very small (2%) margin of the best continuous prompt of the same size for the task. We provide intuitions behind this odd and surprising behavior, as well as extensive empirical analyses quantifying the effect of various parameters. For instance, for larger model sizes we observe higher waywardness, i.e, we can find prompts that more closely map to any arbitrary text with a smaller drop in accuracy. These findings have important implications relating to the difficulty of faithfully interpreting continuous prompts and their generalization across models and tasks, providing guidance for future progress in prompting language models.", "comment": " Comments: Work in Progress "}, {"arxiv": {"page": "https://arxiv.org/abs/2112.07868", "id": "2112.07868", "pdf": "https://arxiv.org/pdf/2112.07868", "other": "https://arxiv.org/format/2112.07868"}, "title": "Few-shot Instruction Prompts for Pretrained Language Models to Detect Social Biases", "author_info": ["Shrimai Prabhumoye", "Rafal Kocielnik", "Mohammad Shoeybi", "Anima Anandkumar", "Bryan Catanzaro"], "summary": "Detecting social bias in text is challenging due to nuance, subjectivity, and difficulty in obtaining good quality labeled datasets at scale, especially given the evolving nature of social biases and society. To address these challenges, we propose a few-shot instruction-based method for prompting pre-trained language models (LMs). We select a few label-balanced exemplars from a small support repository that are closest to the query to be labeled in the embedding space. We then provide the LM with instruction that consists of this subset of labeled exemplars, the query text to be classified, a definition of bias, and prompt it to make a decision. We demonstrate that large LMs used in a few-shot context can detect different types of fine-grained biases with similar and sometimes superior accuracy to fine-tuned models. We observe that the largest 530B parameter model is significantly more effective in detecting social bias compared to smaller models (achieving at least 20% improvement in AUC metric compared to other models). It also maintains a high AUC (dropping less than 5%) in a few-shot setting with a labeled repository reduced to as few as 100 samples. Large pretrained language models thus make it easier and quicker to build new bias detectors.", "comment": ""}, {"arxiv": {"page": "https://arxiv.org/abs/2112.05864", "id": "2112.05864", "pdf": "https://arxiv.org/pdf/2112.05864", "other": "https://arxiv.org/format/2112.05864"}, "title": "Probing the incompressibility of nuclear matter at ultra-high density through the prompt collapse of asymmetric neutron star binaries", "author_info": ["A. Perego", "D. Logoteta", "D. Radice", "S. Bernuzzi", "R. Kashyap", "A. Das", "S. Padamata", "A. Prakash"], "summary": "Using 250 neutron star merger simulations with microphysics, we explore for the first time the role of nuclear incompressibility in the prompt collapse threshold for binaries with different mass ratios. We demonstrate that observations of prompt collapse thresholds, either from binaries with two different mass ratios or with one mass ratio but combined with the knowledge of the maximum neutron star mass or compactness, will constrain the incompressibility at the maximum neutron star density, Kmax, to within tens of percent. This, otherwise inaccessible, measure of Kmax can potentially reveal the presence of hyperons or quarks inside neutron stars.", "comment": " Comments: 8 pages, 5 figures, 2 tables "}, {"arxiv": {"page": "https://arxiv.org/abs/2112.05717", "id": "2112.05717", "pdf": "https://arxiv.org/pdf/2112.05717", "other": "https://arxiv.org/format/2112.05717"}, "title": "Discourse-Aware Prompt Design for Text Generation", "author_info": ["Marjan Ghazvininejad", "Vladimir Karpukhin", "Asli Celikyilmaz"], "summary": "Current efficient fine-tuning methods (e.g., adapters, prefix-tuning, etc.) have optimized conditional text generation via training a small set of extra parameters of the neural language model, while freezing the rest for efficiency. While showing strong performance on some generation tasks, they don't generalize across all generation tasks. In this work, we show that prompt based conditional text generation can be improved with simple and efficient methods that simulate modeling the discourse structure of human written text. We introduce two key design choices: First we show that a higher-level discourse structure of human written text can be modelled with \\textit{hierarchical blocking} on prefix parameters that enable spanning different parts of the input and output text and yield more coherent output generations. Second, we propose sparse prefix tuning by introducing \\textit{attention sparsity} on the prefix parameters at different layers of the network and learn sparse transformations on the softmax-function, respectively. We find that sparse attention enables the prefix-tuning to better control of the input contents (salient facts) yielding more efficient tuning of the prefix-parameters. Experiments on a wide-variety of text generation tasks show that structured design of prefix parameters can achieve comparable results to fine-tuning all parameters while outperforming standard prefix-tuning on all generation tasks even in low-resource settings.", "comment": ""}, {"arxiv": {"page": "https://arxiv.org/abs/2112.05587", "id": "2112.05587", "pdf": "https://arxiv.org/pdf/2112.05587", "other": "https://arxiv.org/format/2112.05587"}, "title": "Unified Multimodal Pre-training and Prompt-based Tuning for Vision-Language Understanding and Generation", "author_info": ["Tianyi Liu", "Zuxuan Wu", "Wenhan Xiong", "Jingjing Chen", "Yu-Gang Jiang"], "summary": "Most existing vision-language pre-training methods focus on understanding tasks and use BERT-like objectives (masked language modeling and image-text matching) during pretraining. Although they perform well in many understanding downstream tasks, e.g., visual question answering, image-text retrieval and visual entailment, they do not possess the ability to generate. To tackle this problem, we propose Unified multimodal pre-training for both Vision-Language understanding and generation (UniVL). The proposed UniVL is capable of handling both understanding tasks and generative tasks. We augment existing pretraining paradigms that only use random masks with causal masks, i.e., triangular masks that mask out future tokens, such that the pre-trained models can have autoregressive generation abilities by design. We formulate several previous understanding tasks as a text generation task and propose to use prompt-based method for fine-tuning on different downstream tasks. Our experiments show that there is a trade-off between understanding tasks and generation tasks while using the same model, and a feasible way to improve both tasks is to use more data. Our UniVL framework attains comparable performance to recent vision-language pre-training methods on both understanding tasks and generation tasks. Moreover, we demostrate that prompt-based finetuning is more data-efficient - it outperforms discriminative methods in few-shot scenarios.", "comment": ""}, {"arxiv": {"page": "https://arxiv.org/abs/2112.04539", "id": "2112.04539", "pdf": "https://arxiv.org/pdf/2112.04539", "other": "https://arxiv.org/format/2112.04539"}, "title": "Prompt-based Zero-shot Relation Classification with Semantic Knowledge Augmentation", "author_info": ["Jiaying Gong", "Hoda Eldardiry"], "summary": "Recognizing unseen relations with no training instances is a challenging task in the real world. In this paper, we propose a prompt-based model with semantic knowledge augmentation (ZS-SKA) to recognize unseen relations under the zero-shot setting. We generate augmented instances with unseen relations from instances with seen relations following a new word-level sentence translation rule. We design prompts based on an external knowledge graph to integrate semantic knowledge information learned from seen relations. Instead of using the actual label sets in the prompt template, we construct weighted virtual label words. By generating the representations of both seen and unseen relations with augmented instances and prompts through prototypical networks, distance is calculated to predict unseen relations. Extensive experiments conducted on three public datasets show that ZS-SKA outperforms state-of-the-art methods under the zero-shot scenarios. Our experimental results also demonstrate the effectiveness and robustness of ZS-SKA.", "comment": " Comments: 11 pages, 7 figures "}, {"arxiv": {"page": "https://arxiv.org/abs/2112.04478", "id": "2112.04478", "pdf": "https://arxiv.org/pdf/2112.04478", "other": "https://arxiv.org/format/2112.04478"}, "title": "Prompting Visual-Language Models for Efficient Video Understanding", "author_info": ["Chen Ju", "Tengda Han", "Kunhao Zheng", "Ya Zhang", "Weidi Xie"], "summary": "Visual-language pre-training has shown great success for learning joint visual-textual representations from large-scale web data, demonstrating remarkable ability for zero-shot generalisation. This paper presents a simple method to efficiently adapt one pre-trained visual-language model to novel tasks with minimal training, and here, we consider video understanding tasks. Specifically, we propose to optimise a few random vectors, termed as continuous prompt vectors, that convert the novel tasks into the same format as the pre-training objectives. In addition, to bridge the gap between static images and videos, temporal information is encoded with lightweight Transformers stacking on top of frame-wise visual features. Experimentally, we conduct extensive ablation studies to analyse the critical components and necessities. On 9 public benchmarks of action recognition, action localisation, and text-video retrieval, across closed-set, few-shot, open-set scenarios, we achieve competitive or state-of-the-art performance to existing methods, despite training significantly fewer parameters.", "comment": " Comments: Project page: https://ju-chen.github.io/efficient-prompt/ "}, {"arxiv": {"page": "https://arxiv.org/abs/2112.03002", "id": "2112.03002", "pdf": "https://arxiv.org/pdf/2112.03002", "other": "https://arxiv.org/format/2112.03002"}, "title": "GraphPrompt: Biomedical Entity Normalization Using Graph-based Prompt Templates", "author_info": ["Jiayou Zhang", "Zhirui Wang", "Shizhuo Zhang", "Megh Manoj Bhalerao", "Yucong Liu", "Dawei Zhu", "Sheng Wang"], "summary": "Biomedical entity normalization unifies the language across biomedical experiments and studies, and further enables us to obtain a holistic view of life sciences. Current approaches mainly study the normalization of more standardized entities such as diseases and drugs, while disregarding the more ambiguous but crucial entities such as pathways, functions and cell types, hindering their real-world applications. To achieve biomedical entity normalization on these under-explored entities, we first introduce an expert-curated dataset OBO-syn encompassing 70 different types of entities and 2 million curated entity-synonym pairs. To utilize the unique graph structure in this dataset, we propose GraphPrompt, a prompt-based learning approach that creates prompt templates according to the graphs. GraphPrompt obtained 41.0% and 29.9% improvement on zero-shot and few-shot settings respectively, indicating the effectiveness of these graph-based prompt templates. We envision that our method GraphPrompt and OBO-syn dataset can be broadly applied to graph-based NLP tasks, and serve as the basis for analyzing diverse and accumulating biomedical data.", "comment": " Comments: 12 pages "}, {"arxiv": {"page": "https://arxiv.org/abs/2112.02917", "id": "2112.02917", "pdf": "https://arxiv.org/pdf/2112.02917", "other": "https://arxiv.org/format/2112.02917"}, "title": "Flares in gamma-ray burst X-ray afterglows as prompt emission from slightly misaligned structured jets", "author_info": ["Rapha\u00ebl Duque", "Paz Beniamini", "Fr\u00e9d\u00e9ric Daigne", "Robert Mochkovitch"], "summary": "We develop a model to explain the flaring activity in gamma-ray burst X-ray afterglows within the framework of slightly misaligned observers to structured jets. We suggest that flares could be the manifestation of prompt dissipation within the core of the jet, appearing to a misaligned observer in the X-ray band because of less favorable Doppler boosting. These flares appear during the afterglow phase because of core--observer light travel delays. In this picture, the prompt emission recorded by this observer comes from material along their line of sight, in the lateral structure of the jet, outside the jet's core. We start by laying down the basic analytical framework to determine the flares characteristics as a function of those of the gamma-ray pulse an aligned observer would have seen. We show that, for typical flare observing times and luminosities, there is indeed viable parameter space to explain flares in this way. We then analytically explore this model and show that it naturally produces flares with small width, a salient observed property of flares. We perform fits of our model to two Swift/XRT flares representing two different types of morphology, to show that our model can capture both. The ejection time of the core jet material responsible of the flare is a critical parameter. While it always remains small compared to the observed time of the flare, confirming that our model does not require very late central engine activity, late ejection times are strongly favored, sometimes larger than the observed duration of the parent gamma-ray burst's prompt phase as measured by T90.", "comment": " Comments: Main text 11 pages, 4 figures and 2 tables. Submitted to MNRAS; comments welcome "}, {"arxiv": {"page": "https://arxiv.org/abs/2112.01518", "id": "2112.01518", "pdf": "https://arxiv.org/pdf/2112.01518", "other": "https://arxiv.org/format/2112.01518"}, "title": "DenseCLIP: Language-Guided Dense Prediction with Context-Aware Prompting", "author_info": ["Yongming Rao", "Wenliang Zhao", "Guangyi Chen", "Yansong Tang", "Zheng Zhu", "Guan Huang", "Jie Zhou", "Jiwen Lu"], "summary": "Recent progress has shown that large-scale pre-training using contrastive image-text pairs can be a promising alternative for high-quality visual representation learning from natural language supervision. Benefiting from a broader source of supervision, this new paradigm exhibits impressive transferability to downstream classification tasks and datasets. However, the problem of transferring the knowledge learned from image-text pairs to more complex dense prediction tasks has barely been visited. In this work, we present a new framework for dense prediction by implicitly and explicitly leveraging the pre-trained knowledge from CLIP. Specifically, we convert the original image-text matching problem in CLIP to a pixel-text matching problem and use the pixel-text score maps to guide the learning of dense prediction models. By further using the contextual information from the image to prompt the language model, we are able to facilitate our model to better exploit the pre-trained knowledge. Our method is model-agnostic, which can be applied to arbitrary dense prediction systems and various pre-trained visual backbones including both CLIP models and ImageNet pre-trained models. Extensive experiments demonstrate the superior performance of our methods on semantic segmentation, object detection, and instance segmentation tasks. Code is available at https://github.com/raoyongming/DenseCLIP", "comment": " Comments: Project page: https://denseclip.ivg-research.xyz "}, {"arxiv": {"page": "https://arxiv.org/abs/2111.14301", "id": "2111.14301", "pdf": "https://arxiv.org/pdf/2111.14301", "other": "https://arxiv.org/format/2111.14301"}, "title": "PSG: Prompt-based Sequence Generation for Acronym Extraction", "author_info": ["Bin Li", "Fei Xia", "Yixuan Weng", "Xiusheng Huang", "Bin Sun", "Shutao Li"], "summary": "Acronym extraction aims to find acronyms (i.e., short-forms) and their meanings (i.e., long-forms) from the documents, which is important for scientific document understanding (SDU@AAAI-22) tasks. Previous works are devoted to modeling this task as a paragraph-level sequence labeling problem. However, it lacks the effective use of the external knowledge, especially when the datasets are in a low-resource setting. Recently, the prompt-based method with the vast pre-trained language model can significantly enhance the performance of the low-resourced downstream tasks. In this paper, we propose a Prompt-based Sequence Generation (PSG) method for the acronym extraction task. Specifically, we design a template for prompting the extracted acronym texts with auto-regression. A position extraction algorithm is designed for extracting the position of the generated answers. The results on the acronym extraction of Vietnamese and Persian in a low-resource setting show that the proposed method outperforms all other competitive state-of-the-art (SOTA) methods.", "comment": " Comments: Accepted for Artificial Intelligence on Scientific Document Understanding (SDU) workshop at AAAI 2022 "}, {"arxiv": {"page": "https://arxiv.org/abs/2111.14163", "id": "2111.14163", "pdf": "https://arxiv.org/pdf/2111.14163", "other": "https://arxiv.org/format/2111.14163"}, "title": "GRB prompt phase spectra under backscattering dominated model", "author_info": ["Mukesh Kumar Vyas", "Asaf Pe'er", "David Eichler"], "summary": "We propose a backscattering dominated prompt emission model for gamma-ray bursts (GRB) prompt phase in which the photons generated through pair annihilation at the centre of the burst are backscattered through Compton scattering by an outflowing stellar cork. We show that the obtained spectra are capable of explaining the low and high energy slopes as well as the distribution of spectral peak energies in their observed prompt spectra.", "comment": " Comments: 6 pages, 5 figures "}, {"arxiv": {"page": "https://arxiv.org/abs/2111.13440", "id": "2111.13440", "pdf": "https://arxiv.org/pdf/2111.13440", "other": "https://arxiv.org/format/2111.13440"}, "title": "True Few-Shot Learning with Prompts -- A Real-World Perspective", "author_info": ["Timo Schick", "Hinrich Sch\u00fctze"], "summary": "Prompt-based approaches are strong at few-shot learning. However, Perez et al. (2021) have recently cast doubt on their performance because they had difficulty getting good results in a \"true\" few-shot setting in which prompts and hyperparameters cannot be tuned on a dev set. In view of this, we conduct an extensive study of PET, a method that combines textual instructions with example-based finetuning. We show that, if correctly configured, PET performs strongly in a true few-shot setting, i.e., without a dev set. Crucial for this strong performance is PET's ability to intelligently handle multiple prompts. We then put our findings to a real-world test by running PET on RAFT, a benchmark of tasks taken directly from realistic NLP applications for which no labeled dev or test sets are available. PET achieves a new state of the art on RAFT and performs close to non-expert humans for 7 out of 11 tasks. These results demonstrate that prompt-based learners like PET excel at true few-shot learning and underpin our belief that learning from instructions will play an important role on the path towards human-like few-shot learning capabilities.", "comment": ""}, {"arxiv": {"page": "https://arxiv.org/abs/2111.12853", "id": "2111.12853", "pdf": "https://arxiv.org/pdf/2111.12853", "other": "https://arxiv.org/format/2111.12853"}, "title": "Amortized Prompt: Lightweight Fine-Tuning for CLIP in Domain Generalization", "author_info": ["Xin Zhang", "Yusuke Iwasawa", "Yutaka Matsuo", "Shixiang Shane Gu"], "summary": "Domain generalization (DG) is a difficult transfer learning problem aiming to learn a generalizable model to unseen domains. Recent massive pre-trained models such as CLIP and GPT-3, i.e. foundation models (FMs), have been shown to be robust to many distribution shifts and therefore should lead to substantial improvements in DG. In this work, we study generic ways to adopt CLIP for DG problems in image classification, where we evaluate on naive zero-shot learning and full DG learning settings. For the latter, we propose AP (Amortized Prompt), as a novel approach for domain inference in the form of prompt generation. Using several standard datasets on domain generalization benchmark, namely PACS, VLCS, OfficeHome, and TerraIncognita, CLIP provides comparable performance without fine-tuning any parameters, suggesting the applicability and importance of FM in DG. In addition, we show that combining domain prompt inference with CLIP enables AP to outperform strong baselines and the naive CLIP baselines by a large margin, raising accuracy from 71.3\\% to 79.3\\%. We hope the simplicity and success of our approach emphasizes the importance of and leads to wider more adoption and analysis of foundation models in the field of domain generalization.", "comment": ""}, {"arxiv": {"page": "https://arxiv.org/abs/2111.08284", "id": "2111.08284", "pdf": "https://arxiv.org/pdf/2111.08284", "other": "https://arxiv.org/format/2111.08284"}, "title": "Few-Shot Self-Rationalization with Natural Language Prompts", "author_info": ["Ana Marasovi\u0107", "Iz Beltagy", "Doug Downey", "Matthew E. Peters"], "summary": "Self-rationalization models that predict task labels and generate free-text elaborations for their predictions could enable more intuitive interaction with NLP systems. These models are, however, currently trained with a large amount of human-written free-text explanations for each task which hinders their broader usage. We propose to study a more realistic setting of self-rationalization using few training examples. We present FEB -- a standardized collection of four existing English-language datasets and associated metrics. We identify the right prompting approach by extensively exploring natural language prompts on FEB. Then, by using this prompt and scaling the model size, we demonstrate that making progress on few-shot self-rationalization is possible. We show there is still ample room for improvement in this task: the average plausibility of generated explanations assessed by human annotators is at most 51%, while plausibility of human explanations is 76%. We hope that FEB together with our proposed approach will spur the community to take on the few-shot self-rationalization challenge.", "comment": " Comments: First two authors contributed equally "}, {"arxiv": {"page": "https://arxiv.org/abs/2111.06719", "id": "2111.06719", "pdf": "https://arxiv.org/pdf/2111.06719", "other": "https://arxiv.org/format/2111.06719"}, "title": "On Transferability of Prompt Tuning for Natural Language Understanding", "author_info": ["Yusheng Su", "Xiaozhi Wang", "Yujia Qin", "Chi-Min Chan", "Yankai Lin", "Zhiyuan Liu", "Peng Li", "Juanzi Li", "Lei Hou", "Maosong Sun", "Jie Zhou"], "summary": "Prompt tuning (PT) is a promising parameter-efficient method to utilize extremely large pre-trained language models (PLMs), which could achieve comparable performance to full-parameter fine-tuning by only tuning a few soft prompts. However, compared to fine-tuning, PT empirically requires much more training steps. To explore whether we can improve the efficiency of PT by reusing trained soft prompts and sharing learned knowledge, we empirically investigate the transferability of soft prompts across different tasks and models. In cross-task transfer, we find that trained soft prompts can well transfer to similar tasks and initialize PT for them to accelerate training and improve performance. Moreover, to explore what factors influence prompts' transferability across tasks, we investigate how to measure the prompt similarity and find that the overlapping rate of activated neurons highly correlates to the transferability. In cross-model transfer, we explore how to project the prompts of a PLM to another PLM and successfully train a kind of projector which can achieve non-trivial transfer performance on similar tasks. However, initializing PT with the projected prompts does not work well, which may be caused by optimization preferences and PLMs' high redundancy. Our findings show that improving PT with knowledge transfer is possible and promising, while prompts' cross-task transferability is generally better than the cross-model transferability.", "comment": ""}, {"arxiv": {"page": "https://arxiv.org/abs/2111.05183", "id": "2111.05183", "pdf": "https://arxiv.org/pdf/2111.05183", "other": "https://arxiv.org/format/2111.05183"}, "title": "Numerical relativity simulations of prompt collapse mergers: threshold mass and phenomenological constraints on neutron star properties after GW170817", "author_info": ["Rahul Kashyap", "Abhishek Das", "David Radice", "Surendra Padamata", "Aviral Prakash", "Domenico Logoteta", "Albino Perego", "Daniel A. Godzieba", "Sebastiano Bernuzzi", "Ignazio Bombaci", "Farrukh J. Fattoyev", "Brendan T. Reed", "Andr\u00e9 da Silva Schneider"], "summary": "We determine the threshold mass for prompt (no bounce) black hole formation in equal-mass neutron star (NS) mergers using a new set of 227 numerical relativity simulations. We consider 23 phenomenological and microphysical finite temperature equations of state (EOS), including models with hyperons and first-order phase transitions to deconfined quarks. We confirm the existence of EOS-insensitive relations between the threshold mass, the binary tidal parameter at the threshold (\u039bth), the maximum mass of nonrotating NSs, and the radii of reference mass NSs. We correct the systematic errors in previously reported fitting coefficients that were obtained with approximate general-relativity simulations. We combine the EOS-insensitive relations, phenomenological constraints on NS properties and observational data from GW170817 to derive an improved lower limit on radii of maximum mass and 1.6 M\u2299 NS of 9.81 km and 10.90 km, respectively. We also constrain the radius and quadrupolar tidal deformability (\u039b) of a 1.4 M\u2299 NS to be larger than 10.74 km and 172, respectively. We consider uncertainties in all independent parameters -- fitting coefficients as well as GW170817 masses while reporting the range of radii constraints. We introduce new methods to constrain the upper as well as lower limit of NS maximum mass using future BNS detections and their identification as prompt or delayed collapse. With future observations it will be possible to derive even tighter constraints on the properties of matter at and above nuclear density using the method proposed in this work.", "comment": " Comments: Comments and suggestions are highly welcomed "}, {"arxiv": {"page": "https://arxiv.org/abs/2111.02643", "id": "2111.02643", "pdf": "https://arxiv.org/pdf/2111.02643", "other": "https://arxiv.org/format/2111.02643"}, "title": "Response Generation with Context-Aware Prompt Learning", "author_info": ["Xiaodong Gu", "Kang Min Yoo", "Sang-Woo Lee"], "summary": "Pre-trained language models (PLM) have marked a huge leap in neural dialogue modeling. While PLMs are pre-trained on large-scale text corpora, they are usually fine-tuned on scarce dialogue data with specific domain knowledge and dialogue styles. However, tailoring the language models while fully utilizing prior knowledge in large pre-trained models remains a challenge. In this paper, we present a novel approach for pre-trained dialogue modeling that casts the dialogue generation problem as a prompt-learning task. Instead of fine-tuning on limited dialogue data, our approach, DialogPrompt, learns continuous prompt embeddings optimized for dialogue contexts, which appropriately elicit knowledge from the large pre-trained model. To encourage the model to better utilize the prompt embeddings, the prompt encoders are designed to be dynamically generated based on the dialogue context. Experiments on popular conversation datasets show that our approach significantly outperforms the fine-tuning baseline and the generic prompt-learning methods. Furthermore, human evaluations strongly support the superiority of DialogPrompt in regard to response generation quality.", "comment": ""}, {"arxiv": {"page": "https://arxiv.org/abs/2111.01998", "id": "2111.01998", "pdf": "https://arxiv.org/pdf/2111.01998", "other": "https://arxiv.org/format/2111.01998"}, "title": "OpenPrompt: An Open-source Framework for Prompt-learning", "author_info": ["Ning Ding", "Shengding Hu", "Weilin Zhao", "Yulin Chen", "Zhiyuan Liu", "Hai-Tao Zheng", "Maosong Sun"], "summary": "Prompt-learning has become a new paradigm in modern natural language processing, which directly adapts pre-trained language models (PLMs) to cloze-style prediction, autoregressive modeling, or sequence to sequence generation, resulting in promising performances on various tasks. However, no standard implementation framework of prompt-learning is proposed yet, and most existing prompt-learning codebases, often unregulated, only provide limited implementations for specific scenarios. Since there are many details such as templating strategy, initializing strategy, and verbalizing strategy, etc. need to be considered in prompt-learning, practitioners face impediments to quickly adapting the desired prompt learning methods to their applications. In this paper, we present {OpenPrompt}, a unified easy-to-use toolkit to conduct prompt-learning over PLMs. OpenPrompt is a research-friendly framework that is equipped with efficiency, modularity, and extendibility, and its combinability allows the freedom to combine different PLMs, task formats, and prompting modules in a unified paradigm. Users could expediently deploy prompt-learning frameworks and evaluate the generalization of them on different NLP tasks without constraints. OpenPrompt is publicly released at {\\url{ https://github.com/thunlp/OpenPrompt}}.", "comment": ""}, {"arxiv": {"page": "https://arxiv.org/abs/2111.01193", "id": "2111.01193", "pdf": "https://arxiv.org/pdf/2111.01193", "other": "https://arxiv.org/format/2111.01193"}, "title": "Transformers for prompt-level EMA non-response prediction", "author_info": ["Supriya Nagesh", "Alexander Moreno", "Stephanie M. Carpenter", "Jamie Yap", "Soujanya Chatterjee", "Steven Lloyd Lizotte", "Neng Wan", "Santosh Kumar", "Cho Lam", "David W. Wetter", "Inbal Nahum-Shani", "James M. Rehg"], "summary": "Ecological Momentary Assessments (EMAs) are an important psychological data source for measuring current cognitive states, affect, behavior, and environmental factors from participants in mobile health (mHealth) studies and treatment programs. Non-response, in which participants fail to respond to EMA prompts, is an endemic problem. The ability to accurately predict non-response could be utilized to improve EMA delivery and develop compliance interventions. Prior work has explored classical machine learning models for predicting non-response. However, as increasingly large EMA datasets become available, there is the potential to leverage deep learning models that have been effective in other fields. Recently, transformer models have shown state-of-the-art performance in NLP and other domains. This work is the first to explore the use of transformers for EMA data analysis. We address three key questions in applying transformers to EMA data: 1. Input representation, 2. encoding temporal information, 3. utility of pre-training on improving downstream prediction task performance. The transformer model achieves a non-response prediction AUC of 0.77 and is significantly better than classical ML and LSTM-based deep learning models. We will make our a predictive model trained on a corpus of 40K EMA samples freely-available to the research community, in order to facilitate the development of future transformer-based EMA analysis works.", "comment": ""}, {"arxiv": {"page": "https://arxiv.org/abs/2111.00958", "id": "2111.00958", "pdf": "https://arxiv.org/pdf/2111.00958", "other": "https://arxiv.org/format/2111.00958"}, "title": "Evolution of equal mass binary bare quark stars in full general relativity: could a supramassive merger remnant experience prompt collapse?", "author_info": ["Enping Zhou", "Kenta Kiuchi", "Masaru Shibata", "Antonios Tsokaros", "Koji Uryu"], "summary": "We have evolved mergers of equal-mass binary quark stars, the total mass of which is close to the mass shedding limit of uniformly rotating configurations, in fully general relativistic hydrodynamic simulations, aimed at investigating the post-merger outcomes. In particular, we have identified the threshold mass for prompt black hole formation after the merger, by tracing the minimum lapse function as well as the amount of ejected material during the merger simulation. A semi-analytical investigation based on the angular momentum contained in the merger remnant is also performed to verify the results. For the equation of state considered in this work, the maximum mass of TOV solutions for which is 2.10 M\u2299, the threshold mass is found between 3.05 and 3.10 M\u2299. This result is consistent (with a quantitative error smaller than 1%) with the universal relation derived from the numerical results of symmetric binary neutron star mergers. Contrary to the neutron star case, the threshold mass is close to the mass shedding limit of uniformly rotating quark star. Consequently, we have found that binary quark stars with total mass corresponding to the long-lived supramassive remnant for neutron star case, could experience collapse to black hole within several times dynamical timescale, making quark stars as exceptions of the commonly accepted post-merger scenarios for binary neutron star mergers. We have suggested explanation for both the similarity and the difference, between quark stars and neutron stars.", "comment": " Comments: 6 pages, 4 figures. Comments are welcome "}, {"arxiv": {"page": "https://arxiv.org/abs/2111.00865", "id": "2111.00865", "pdf": "https://arxiv.org/pdf/2111.00865", "other": "https://arxiv.org/format/2111.00865"}, "title": "MEmoBERT: Pre-training Model with Prompt-based Learning for Multimodal Emotion Recognition", "author_info": ["Jinming Zhao", "Ruichen Li", "Qin Jin", "Xinchao Wang", "Haizhou Li"], "summary": "Multimodal emotion recognition study is hindered by the lack of labelled corpora in terms of scale and diversity, due to the high annotation cost and label ambiguity. In this paper, we propose a pre-training model \\textbf{MEmoBERT} for multimodal emotion recognition, which learns multimodal joint representations through self-supervised learning from large-scale unlabeled video data that come in sheer volume. Furthermore, unlike the conventional \"pre-train, finetune\" paradigm, we propose a prompt-based method that reformulates the downstream emotion classification task as a masked text prediction one, bringing the downstream task closer to the pre-training. Extensive experiments on two benchmark datasets, IEMOCAP and MSP-IMPROV, show that our proposed MEmoBERT significantly enhances emotion recognition performance.", "comment": " Comments: 4 papges, 2 figures "}, {"arxiv": {"page": "https://arxiv.org/abs/2110.14792", "id": "2110.14792", "pdf": "https://arxiv.org/pdf/2110.14792", "other": "https://arxiv.org/format/2110.14792"}, "title": "On explaining prompt emission from GRB central engines with photospheric emission model", "author_info": ["Mukul Bhattacharya", "Pawan Kumar"], "summary": "Although the observed spectra for gamma-ray burst (GRB) prompt emission is well constrained, the underlying radiation mechanism is still not very well understood. We explore photospheric emission in GRB jets by modelling the Comptonization of fast cooled synchrotron photons whilst the electrons and protons are accelerated to highly relativistic energies by repeated energy dissipation events as well as Coulomb collisions. In contrast to the previous simulations, we implement realistic photon-to-particle number ratios of N\u03b3/Ne\u223c105 or higher, that are consistent with the observed radiation efficiency of relativistic jets. Using our Monte Carlo radiation transfer (MCRaT) code, we can successfully model the prompt emission spectra when the electrons are momentarily accelerated to highly relativistic energies (Lorentz factor \u223c50\u2212100) after getting powered by \u223c30\u221250 episodic dissipation events in addition to their Coulomb coupling with the jet protons, and for baryonic outflows that originate from moderate optical depths \u223c20\u221230. We also show that the resultant shape of the photon spectrum is practically independent of the initial photon energy distribution and the jet baryonic energy content, and hence independent of the emission mechanism.", "comment": " Comments: 15 pages including 5 figures; based on the talk given in the 16th Marcel Grossmann Meeting (MG16) held during July 5-10, 2021; to appear in the proceedings of MG16 "}, {"arxiv": {"page": "https://arxiv.org/abs/2110.12410", "id": "2110.12410", "pdf": "https://arxiv.org/pdf/2110.12410", "other": "https://arxiv.org/format/2110.12410"}, "title": "Nature of the ultrarelativistic prompt emission phase of GRB 190114C", "author_info": ["R. Moradi", "J. A. Rueda", "R. Ruffini", "Liang Li", "C. L. Bianco", "S. Campion", "C. Cherubini", "S. Filippi", "Y. Wang", "S. S. Xue"], "summary": "We address the physical origin of the ultrarelativistic prompt emission (UPE) phase of GRB 190114C observed in the interval 1.9-3.99 s, by the Fermi-GBM in 10 keV-10 MeV . Thanks to high S/N ratio of Fermi-GBM data, a time resolved spectral analysis has evidenced a sequence of similar blackbody plus cutoff power-law spectra, on ever decreasing time intervals during the entire UPE phase. We assume that during the UPE phase, the inner engine of the GRB, composed of a Kerr black hole and a uniform test magnetic field B0, aligned with the BH rotation axis, operates in an overcritical field. We infer an e+e\u2212 pair electromagnetic plasma in presence of a baryon load, a PEMB pulse, originating from a vacuum polarization quantum process in the inner engine. This initially optically thick plasma self-accelerates, giving rise at the transparency radius to the MeV radiation observed by Ferm-GBM. At trf > 3.99 s, the electric field becomes undercritical, and the inner engine operates in the classical electrodynamics regime and generate the GeV emission. During both the quantum and the classical electrodynamics processes, we determine the time varying mass and spin of the Kerr BH in the inner engine, fulfilling the Christodoulou-Hawking-Ruffini mass-energy formula. For the first time, we quantitatively show how the inner engine, by extracting the rotational energy of the Kerr BH, produces a series of PEMB pulses. We follow the quantum vacuum polarization process in sequences with decreasing time bins. We compute the Lorentz factors, the baryon loads and the radii at transparency, as well as the value of the magnetic field, assumed to be constant in each sequence. The fundamental hierarchical structure, linking the quantum electrodynamics regime to the classical electrodynamics regime, is characterized by the emission of blackholic quanta with a timescale t=10\u22129s, and energy E=1045 erg.", "comment": " Journal ref:         PRD 104, 063043 - Published 29 September 2021       "}, {"arxiv": {"page": "https://arxiv.org/abs/2110.12190", "id": "2110.12190", "pdf": "https://arxiv.org/pdf/2110.12190", "other": "https://arxiv.org/format/2110.12190"}, "title": "PROMPT: Parallel Iterative Algorithm for \u2113p norm linear regression via Majorization Minimization with an application to semi-supervised graph learning", "author_info": ["R. Jyothi", "P. Babu"], "summary": "In this paper, we consider the problem of \u2113p norm linear regression, which has several applications such as in sparse recovery, data clustering, and semi-supervised learning. The problem, even though convex, does not enjoy a closed-form solution. The state-of-the-art algorithms are iterative but suffer from convergence issues, i.e., they either diverge for p>3 or the convergence to the optimal solution is sensitive to the initialization of the algorithm. Also, these algorithms are not generalizable to every possible value of p. In this paper, we propose an iterative algorithm : Parallel IteRative AlgOrithM for \u2113P norm regression via MajorizaTion Minimization (PROMPT) based on the principle of Majorization Minimization and prove that the proposed algorithm is monotonic and converges to the optimal solution of the problem for any value of p. The proposed algorithm can also parallelly update each element of the regression variable, which helps to handle large scale data efficiently, a common scenario in this era of data explosion. Subsequently, we show that the proposed algorithm can also be applied for the graph based semi-supervised learning problem. We show through numerical simulations that the proposed algorithm converges to the optimal solution for any random initialization and also performs better than the state-of-the-art algorithms in terms of speed of convergence. We also evaluate the performance of the proposed algorithm using simulated and real data for the graph based semi-supervised learning problem.", "comment": ""}, {"arxiv": {"page": "https://arxiv.org/abs/2110.10043", "id": "2110.10043", "pdf": "https://arxiv.org/pdf/2110.10043", "other": "https://arxiv.org/format/2110.10043"}, "title": "Investigating charm production and fragmentation via azimuthal correlations of prompt D mesons with charged particles in pp collisions at s\u221a=13 TeV", "author_info": [" ALICE Collaboration"], "summary": "Angular correlations of heavy-flavour and charged particles in high-energy proton-proton collisions are sensitive to the production mechanisms of heavy quarks and to their fragmentation as well as hadronisation processes. The measurement of the azimuthal-correlation function of prompt D mesons with charged particles in proton-proton collisions at a centre-of-mass energy of s\u221a=13 TeV with the ALICE detector is reported, considering D0, D+, and D\u2217+ mesons in the transverse-momentum interval 3<pT<36 GeV/c at midrapidity (|y|<0.5), and charged particles with pT>0.3 GeV/c and pseudorapidity |\u03b7|<0.8. This measurement has an improved precision and provides an extended transverse-momentum coverage compared to previous ALICE measurements at lower energies. The study is also performed as a function of the charged-particle multiplicity, showing no modifications of the correlation function with multiplicity within uncertainties. The properties and the transverse-momentum evolution of the near- and away-side correlation peaks are studied and compared with predictions from various Monte Carlo event generators. The obtained results can provide constraints on the generators. Among those considered, PYTHIA8 and POWHEG+PYTHIA8 provide the best description of the measured observables.", "comment": " Report number:           CERN-EP-2021-184                                    "}, {"arxiv": {"page": "https://arxiv.org/abs/2110.10016", "id": "2110.10016", "pdf": "https://arxiv.org/pdf/2110.10016", "other": "https://arxiv.org/format/2110.10016"}, "title": "Comparison of the measured atmospheric muon rate with Monte Carlo simulations and sensitivity study for detection of prompt atmospheric muons with KM3NeT", "author_info": ["Piotr Kalaczy\u0144ski"], "summary": "The KM3NeT Collaboration has successfully deployed the first detection units of the next generation undersea neutrino telescopes in the Mediterranean Sea at the two sites in Italy and in France. A sample of the data collected between December 2016 and January 2020 has been used to measure the atmospheric muon rate at two different depths under the sea level: 3.5 km with KM3NeT-ARCA and 2.5 km with KM3NeT-ORCA. Atmospheric muons represent an abundant signal in a neutrino telescope and can be used to test the reliability of the Monte Carlo simulation chain and to study the physics of extensive air showers caused by highly-energetic primary nuclei impinging the Earth's atmosphere. At energies above PeV the contribution from prompt muons, created right after the first interaction in the shower, is expected to become dominant, however its existence has not yet been experimentally confirmed. In this work, data collected with the first detection units of KM3NeT are compared to Monte Carlo simulations based on MUPAGE and CORSIKA codes. The main features of the simulation and reconstruction chains are presented. Additionally, the first results of the simulated signal from the prompt muon component for KM3NeT-ARCA and KM3NeT-ORCA obtained with CORSIKA are discussed.", "comment": " Journal ref:         JINST 16 C09035 (2021)       "}, {"arxiv": {"page": "https://arxiv.org/abs/2110.10006", "id": "2110.10006", "pdf": "https://arxiv.org/pdf/2110.10006", "other": "https://arxiv.org/format/2110.10006"}, "title": "Measurement of prompt D+s-meson production and azimuthal anisotropy in Pb-Pb collisions at sNN\u2212\u2212\u2212\u221a=5.02 TeV", "author_info": [" ALICE Collaboration"], "summary": "The production yield and angular anisotropy of prompt D+s mesons were measured as a function of transverse momentum (pT) in Pb-Pb collisions at a centre-of-mass energy per nucleon pair sNN\u2212\u2212\u2212\u2212\u221a=5.02 TeV collected with the ALICE detector at the LHC. D+s mesons and their charge conjugates were reconstructed at midrapidity (|y|<0.5) from their hadronic decay channel D+s\u2192\u03c6\u03c0+, with \u03c6\u2192K\u2212K+, in the pT intervals 2<pT<50 GeV/c and 2<pT<36 GeV/c for the 0-10% and 30-50% centrality intervals. For pT>10 GeV/c, the measured D+s-meson nuclear modification factor RAA is consistent with the one of non-strange D mesons within uncertainties, while at lower pT a hint for a D+s-meson RAA larger than that of non-strange D mesons is seen. The enhanced production of D+s relative to non-strange D mesons is also studied by comparing the pT-dependent D+s/D0 production yield ratios in Pb-Pb and in pp collisions. The ratio measured in Pb-Pb collisions is found to be on average higher than that in pp collisions in the interval 2<pT<8 GeV/c with a significance of 2.3\u03c3 and 2.4\u03c3 for the 0-10% and 30-50% centrality intervals. The azimuthal anisotropy coefficient v2 of prompt D+s mesons was measured in Pb-Pb collisions in the 30-50% centrality interval and is found to be compatible with that of non-strange D mesons. The main features of the measured RAA, D+s/D0 ratio, and v2 as a function of pT are described by theoretical calculations of charm-quark transport in a hydrodynamically expanding quark-gluon plasma including hadronisation via charm-quark recombination with light quarks from the medium. The pT-integrated production yield of D+s mesons is compatible with the prediction of the statistical hadronisation model.", "comment": " Report number:           CERN-EP-2021-187                                    "}, {"arxiv": {"page": "https://arxiv.org/abs/2110.09420", "id": "2110.09420", "pdf": "https://arxiv.org/pdf/2110.09420", "other": "https://arxiv.org/format/2110.09420"}, "title": "Prompt D0, D+, and D\u2217+ production in Pb-Pb collisions at sNN\u2212\u2212\u2212\u221a = 5.02 TeV", "author_info": [" ALICE Collaboration"], "summary": "The production of prompt D0, D+, and D\u2217+ mesons was measured at midrapidity (|y|< 0.5) in Pb-Pb collisions at the centre-of-mass energy per nucleon-nucleon pair sNN\u2212\u2212\u2212\u221a = 5.02 TeV with the ALICE detector at the LHC. The D mesons were reconstructed via their hadronic decay channels and their production yields were measured in central (0-10%) and semicentral (30-50%) collisions. The measurement was performed up to a transverse momentum (pT) of 36 or 50 GeV/c depending on the D meson species and the centrality interval. For the first time in Pb-Pb collisions at the LHC, the yield of D0 mesons was measured down to pT = 0, which allowed a model-independent determination of the pT-integrated yield per unit of rapidity (dN/dy). A maximum suppression by a factor 5 and 2.5 was observed with the nuclear modification factor (RAA) of prompt D mesons at pT = 6-8 GeV/c for the 0-10% and 30-50% centrality classes, respectively. The D-meson RAA is compared with that of charged pions, charged hadrons, and J/\u03c8 mesons as well as with theoretical predictions. The analysis of the agreement between the measured RAA, elliptic (v2) and triangular (v3) flow, and the model predictions allowed us to constrain the charm spatial diffusion coefficient Ds. Furthermore the comparison of RAA and v2 with different implementations of the same models provides an important insight into the role of radiative energy loss as well as charm quark recombination in the hadronisation mechanisms.", "comment": " Report number:           CERN-EP-2021-213                                    "}, {"arxiv": {"page": "https://arxiv.org/abs/2110.08525", "id": "2110.08525", "pdf": "https://arxiv.org/pdf/2110.08525", "other": "https://arxiv.org/format/2110.08525"}, "title": "The Power of Prompt Tuning for Low-Resource Semantic Parsing", "author_info": ["Nathan Schucher", "Siva Reddy", "Harm de Vries"], "summary": "Prompt tuning has recently emerged as an effective method for adapting pre-trained language models to a number of language tasks. In this paper, we investigate prompt tuning for semantic parsing, the task of mapping natural language utterances onto formal meaning representations. For large T5 models we find (i) that prompt tuning significantly outperforms fine-tuning in the low data regime and (ii) that canonicalization -- i.e. naturalizing the meaning representations -- barely improves performance. This last result is surprising as it suggests that large T5 models can be modulated to generate sequences that are far from the pre-training distribution.", "comment": ""}, {"arxiv": {"page": "https://arxiv.org/abs/2110.08484", "id": "2110.08484", "pdf": "https://arxiv.org/pdf/2110.08484", "other": "https://arxiv.org/format/2110.08484"}, "title": "A Good Prompt Is Worth Millions of Parameters? Low-resource Prompt-based Learning for Vision-Language Models", "author_info": ["Woojeong Jin", "Yu Cheng", "Yelong Shen", "Weizhu Chen", "Xiang Ren"], "summary": "Large pretrained vision-language (VL) models can learn a new task with a handful of examples or generalize to a new task without fine-tuning. However, these gigantic VL models are hard to deploy for real-world applications due to their impractically huge model size and slow inference speed. In this work, we propose FewVLM, a few-shot prompt-based learner on vision-language tasks. We pretrain a sequence-to-sequence Transformer model with both prefix language modeling (PrefixLM) and masked language modeling (MaskedLM), and introduce simple prompts to improve zero-shot and few-shot performance on VQA and image captioning. Experimental results on five VQA and captioning datasets show that \\method\\xspace outperforms Frozen which is 31 times larger than ours by 18.2% point on zero-shot VQAv2 and achieves comparable results to a 246\u00d7 larger model, PICa. We observe that (1) prompts significantly affect zero-shot performance but marginally affect few-shot performance, (2) MaskedLM helps few-shot VQA tasks while PrefixLM boosts captioning performance, and (3) performance significantly increases when training set size is small.", "comment": " Comments: Preprint "}, {"arxiv": {"page": "https://arxiv.org/abs/2110.08387", "id": "2110.08387", "pdf": "https://arxiv.org/pdf/2110.08387", "other": "https://arxiv.org/format/2110.08387"}, "title": "Generated Knowledge Prompting for Commonsense Reasoning", "author_info": ["Jiacheng Liu", "Alisa Liu", "Ximing Lu", "Sean Welleck", "Peter West", "Ronan Le Bras", "Yejin Choi", "Hannaneh Hajishirzi"], "summary": "Despite their ability to capture large amount of knowledge during pretraining, large-scale language models often benefit from incorporating external knowledge bases, especially on commonsense reasoning tasks. This motivates us to explore how we can best leverage knowledge elicited from language models themselves. We propose generating knowledge statements directly from a language model with a generic prompt format, then selecting the knowledge which maximizes prediction probability. Despite its simplicity, this approach improves performance of both off-the-shelf and finetuned language models on four commonsense reasoning tasks, improving the state-of-the-art on numerical commonsense (NumerSense), general commonsense (CommonsenseQA 2.0), and scientific commonsense (QASC) benchmarks. Notably, we find that a model's predictions can improve when using its own generated knowledge, demonstrating the importance of symbolic knowledge representation in neural reasoning processes.", "comment": ""}, {"arxiv": {"page": "https://arxiv.org/abs/2110.08207", "id": "2110.08207", "pdf": "https://arxiv.org/pdf/2110.08207", "other": "https://arxiv.org/format/2110.08207"}, "title": "Multitask Prompted Training Enables Zero-Shot Task Generalization", "author_info": ["Victor Sanh", "Albert Webson", "Colin Raffel", "Stephen H. Bach", "Lintang Sutawika", "Zaid Alyafeai", "Antoine Chaffin", "Arnaud Stiegler", "Teven Le Scao", "Arun Raja", "Manan Dey", "M Saiful Bari", "Canwen Xu", "Urmish Thakker", "Shanya Sharma Sharma", "Eliza Szczechla", "Taewoon Kim", "Gunjan Chhablani", "Nihal Nayak", "Debajyoti Datta", "Jonathan Chang", "Mike Tian-Jian Jiang", "Han Wang", "Matteo Manica", "Sheng Shen"], "summary": "Large language models have recently been shown to attain reasonable zero-shot generalization on a diverse set of tasks (Brown et al., 2020). It has been hypothesized that this is a consequence of implicit multitask learning in language models' pretraining (Radford et al., 2019). Can zero-shot generalization instead be directly induced by explicit multitask learning? To test this question at scale, we develop a system for easily mapping any natural language tasks into a human-readable, prompted form. We convert a large set of supervised datasets, each with multiple prompts with diverse wording. These prompted datasets allow for benchmarking the ability of a model to perform completely unseen tasks. We finetune a pretrained encoder-decoder model (Raffel et al., 2020; Lester et al., 2021) on this multitask mixture covering a wide variety of tasks. The model attains strong zero-shot performance on several standard datasets, often outperforming models up to 16x its size. Further, our approach attains strong performance on a subset of tasks from the BIG-bench benchmark, outperforming models up to 6x its size. All prompts and trained models are available at https://github.com/ bigscience-workshop/promptsource/ and https://huggingface.co/bigscience/T0pp.", "comment": " Comments: https://github.com/bigscience-workshop/promptsource/ "}, {"arxiv": {"page": "https://arxiv.org/abs/2110.08118", "id": "2110.08118", "pdf": "https://arxiv.org/pdf/2110.08118", "other": "https://arxiv.org/format/2110.08118"}, "title": "Few-Shot Bot: Prompt-Based Learning for Dialogue Systems", "author_info": ["Andrea Madotto", "Zhaojiang Lin", "Genta Indra Winata", "Pascale Fung"], "summary": "Learning to converse using only a few examples is a great challenge in conversational AI. The current best conversational models, which are either good chit-chatters (e.g., BlenderBot) or goal-oriented systems (e.g., MinTL), are language models (LMs) fine-tuned on large conversational datasets. Training these models is expensive, both in terms of computational resources and time, and it is hard to keep them up to date with new conversational skills. A simple yet unexplored solution is prompt-based few-shot learning (Brown et al. 2020) which does not require gradient-based fine-tuning but instead uses a few examples in the LM context as the only source of learning. In this paper, we explore prompt-based few-shot learning in dialogue tasks. We benchmark LMs of different sizes in nine response generation tasks, which include four knowledge-grounded tasks, a task-oriented generations task, three open-chat tasks, and controlled stylistic generation, and five conversational parsing tasks, which include dialogue state tracking, graph path generation, persona information extraction, document retrieval, and internet query generation. The current largest released LM (GPT-J-6B) using prompt-based few-shot learning, and thus requiring no training, achieves competitive performance to fully trained state-of-the-art models. Moreover, we propose a novel prompt-based few-shot classifier, that also does not require any fine-tuning, to select the most appropriate prompt given a dialogue history. Finally, by combining the power of prompt-based few-shot learning and a Skill Selector, we create an end-to-end chatbot named the Few-Shot Bot (FSB), which automatically selects the most appropriate conversational skill, queries different knowledge bases or the internet, and uses the retrieved knowledge to generate a human-like response, all using only few dialogue examples per skill.", "comment": ""}, {"arxiv": {"page": "https://arxiv.org/abs/2110.07904", "id": "2110.07904", "pdf": "https://arxiv.org/pdf/2110.07904", "other": "https://arxiv.org/format/2110.07904"}, "title": "SPoT: Better Frozen Model Adaptation through Soft Prompt Transfer", "author_info": ["Tu Vu", "Brian Lester", "Noah Constant", "Rami Al-Rfou", "Daniel Cer"], "summary": "As pre-trained language models have gotten larger, there has been growing interest in parameter-efficient methods to apply these models to downstream tasks. Building on the PromptTuning approach of Lester et al. (2021), which learns task-specific soft prompts to condition a frozen language model to perform downstream tasks, we propose a novel prompt-based transfer learning approach called SPoT: Soft Prompt Transfer. SPoT first learns a prompt on one or more source tasks and then uses it to initialize the prompt for a target task. We show that SPoT significantly boosts the performance of PromptTuning across many tasks. More importantly, SPoT either matches or outperforms ModelTuning, which fine-tunes the entire model on each individual task, across all model sizes while being more parameter-efficient (up to 27,000x fewer task-specific parameters). We further conduct a large-scale study on task transferability with 26 NLP tasks and 160 combinations of source-target tasks, and demonstrate that tasks can often benefit each other via prompt transfer. Finally, we propose a simple yet efficient retrieval approach that interprets task prompts as task embeddings to identify the similarity between tasks and predict the most transferable source tasks for a given novel target task.", "comment": " Comments: 20 pages, 6 figures, 5 tables "}, {"arxiv": {"page": "https://arxiv.org/abs/2110.07867", "id": "2110.07867", "pdf": "https://arxiv.org/pdf/2110.07867", "other": "https://arxiv.org/format/2110.07867"}, "title": "Exploring Low-dimensional Intrinsic Task Subspace via Prompt Tuning", "author_info": ["Yujia Qin", "Xiaozhi Wang", "Yusheng Su", "Yankai Lin", "Ning Ding", "Zhiyuan Liu", "Juanzi Li", "Lei Hou", "Peng Li", "Maosong Sun", "Jie Zhou"], "summary": "How can pre-trained language models (PLMs) learn universal representations and effectively adapt to broad NLP tasks differing a lot superficially? In this work, we empirically find evidences indicating that the adaptations of PLMs to various tasks can be reparameterized as optimizing only a few free parameters in a common low-dimensional intrinsic task subspace, which may help us understand why PLMs could easily adapt to various NLP tasks with small-scale data. Specifically, to find such a subspace and examine its universality, we resort to the recent success of prompt tuning and decompose the soft prompts of multiple NLP tasks into the same low-dimensional nonlinear subspace, then we learn to adapt the PLM to unseen tasks or data by only tuning parameters in the subspace. We dub this pipeline as intrinsic prompt tuning (IPT). In experiments, we study diverse few-shot NLP tasks and surprisingly find that in a 5-dimensional subspace found with 100 random tasks, by only tuning 5 free parameters, we can recover 87% and 65% of the full prompt tuning performance for 100 seen tasks (using different training data) and 20 unseen tasks, respectively, showing great generalization ability of the found intrinsic task subspace. Besides being an analysis tool, IPT could further bring practical benefits, such as improving the prompt tuning stability.", "comment": ""}, {"arxiv": {"page": "https://arxiv.org/abs/2110.07791", "id": "2110.07791", "pdf": "https://arxiv.org/pdf/2110.07791", "other": "https://arxiv.org/format/2110.07791"}, "title": "Overall Spectral Properties of Prompt Emissions with Diverse Segments in Swift/BAT Short Gamma-ray Bursts", "author_info": ["X. J. Li", "Z. B. Zhang", "K. Zhang"], "summary": "Owing to lack of multiple components of prompt \u03b3-ray emissions in short gamma-ray bursts (sGRBs), how these distinct components are correlated still keeps unclear. In this paper, we investigate the spectral and temporal properties of precursors, main peaks and extended emissions in 26 sGRBs including GRB 170817A. It is found that peak energies (Ep) in each pulse are uncorrelated with the pulse duration (tdur). Meanwhile, we find that there is no obvious correlation between peak energy and energy fluence. Interestingly, there is no obvious spectral evolution from earlier precursors to later extended emissions in view of the correlations of tdur with either the Ep or the low energy spectrum index, \u03b1. A power-law correlation between the average flux (Fp) and the energy fluence (S\u03b3), logFp=(0.62\u00b10.07)logS\u03b3+(0.27\u00b10.07), is found to exist in the individual segments instead of mean peaks previously. Furthermore, we also find that the main peaks are on average brighter than the precursors or the extend emissions about one order of magnitude. On the basis of all the above analyses, one can conclude that three emissive components would share the same radiation mechanisms but they might be dominated by diverse physical processes.", "comment": " Journal ref:         A&A 657, A124 (2022)       "}, {"arxiv": {"page": "https://arxiv.org/abs/2110.07602", "id": "2110.07602", "pdf": "https://arxiv.org/pdf/2110.07602", "other": "https://arxiv.org/format/2110.07602"}, "title": "P-Tuning v2: Prompt Tuning Can Be Comparable to Fine-tuning Universally Across Scales and Tasks", "author_info": ["Xiao Liu", "Kaixuan Ji", "Yicheng Fu", "Zhengxiao Du", "Zhilin Yang", "Jie Tang"], "summary": "Prompt tuning, which only tunes continuous prompts with a frozen language model, substantially reduces per-task storage and memory usage at training. However, in the context of NLU, prior work reveals that prompt tuning does not perform well for normal-sized pre-trained models. We also find that existing methods of prompt tuning cannot handle hard sequence tagging tasks, indicating a lack of universality. We present a novel empirical finding that properly optimized prompt tuning can be universally effective across a wide range of model scales and NLU tasks. It matches the performance of fine-tuning while having only 0.1\\%-3\\% tuned parameters. Our method P-Tuning v2 is not a new method, but a version of prefix-tuning \\cite{li2021prefix} optimized and adapted for NLU. Given the universality and simplicity of P-Tuning v2, we believe it can serve as an alternative to fine-tuning and a strong baseline for future research.", "comment": ""}, {"arxiv": {"page": "https://arxiv.org/abs/2110.07298", "id": "2110.07298", "pdf": "https://arxiv.org/pdf/2110.07298", "other": "https://arxiv.org/format/2110.07298"}, "title": "LFPT5: A Unified Framework for Lifelong Few-shot Language Learning Based on Prompt Tuning of T5", "author_info": ["Chengwei Qin", "Shafiq Joty"], "summary": "Existing approaches to lifelong language learning rely on plenty of labeled data for learning a new task, which is hard to obtain in most real scenarios. Considering that humans can continually learn new tasks from a handful of examples, we expect the models also to be able to generalize well on new few-shot tasks without forgetting the previous ones. In this work, we define this more challenging yet practical problem as Lifelong Few-shot Language Learning (LFLL) and propose a unified framework for it based on prompt tuning of T5. Our framework called LFPT5 takes full advantage of PT's strong few-shot learning ability, and simultaneously trains the model as a task solver and a data generator. Before learning a new domain of the same task type, LFPT5 generates pseudo (labeled) samples of previously learned domains, and later gets trained on those samples to alleviate forgetting of previous knowledge as it learns the new domain. In addition, a KL divergence loss is minimized to achieve label consistency between the previous and the current model. While adapting to a new task type, LFPT5 includes and tunes additional prompt embeddings for the new task. With extensive experiments, we demonstrate that LFPT5 can be applied to various different types of tasks and significantly outperform previous methods in different LFLL settings.", "comment": " Comments: ICLR 2022. Code is available at https://github.com/qcwthu/Lifelong-Fewshot-Language-Learning "}, {"arxiv": {"page": "https://arxiv.org/abs/2110.07280", "id": "2110.07280", "pdf": "https://arxiv.org/pdf/2110.07280", "other": "https://arxiv.org/format/2110.07280"}, "title": "P-Adapters: Robustly Extracting Factual Information from Language Models with Diverse Prompts", "author_info": ["Benjamin Newman", "Prafulla Kumar Choubey", "Nazneen Rajani"], "summary": "Recent work (e.g. LAMA (Petroni et al., 2019)) has found that the quality of the factual information extracted from Large Language Models (LLMs) depends on the prompts used to query them. This inconsistency is problematic because different users will query LLMs for the same information using different wording, but should receive the same, accurate responses regardless. In this work we aim to address this shortcoming by introducing P-Adapters: lightweight models that sit between the embedding layer and first attention layer of LLMs. They take LLM embeddings as input and output continuous prompts that are used to query the LLM. Additionally, we investigate Mixture of Experts (MoE) models that learn a set of continuous prompts (\"experts\") and select one to query the LLM. They require a separate classifier trained on human-annotated data to map natural language prompts to the continuous ones. P-Adapters perform comparably to the more complex MoE models in extracting factual information from BERT and RoBERTa while eliminating the need for additional annotations. P-Adapters show between 12-26% absolute improvement in precision and 36-50% absolute improvement in consistency over a baseline of only using natural language queries. Finally, we investigate what makes a P-adapter successful and conclude that access to the LLM's embeddings of the original natural language prompt, particularly the subject of the entity pair being asked about, is a significant factor.", "comment": " Comments: 15 pages, 6 figures, 4 tables "}, {"arxiv": {"page": "https://arxiv.org/abs/2110.06609", "id": "2110.06609", "pdf": "https://arxiv.org/pdf/2110.06609", "other": "https://arxiv.org/format/2110.06609"}, "title": "MSP: Multi-Stage Prompting for Making Pre-trained Language Models Better Translators", "author_info": ["Zhixing Tan", "Xiangwen Zhang", "Shuo Wang", "Yang Liu"], "summary": "Pre-trained language models have recently been shown to be able to perform translation without finetuning via prompting. Inspired by these findings, we study improving the performance of pre-trained language models on translation tasks, where training neural machine translation models is the current de facto approach. We present Multi-Stage Prompting, a simple and lightweight approach for better adapting pre-trained language models to translation tasks. To make pre-trained language models better translators, we divide the translation process via pre-trained language models into three separate stages: the encoding stage, the re-encoding stage, and the decoding stage. During each stage, we independently apply different continuous prompts for allowing pre-trained language models better adapting to translation tasks. We conduct extensive experiments on low-, medium-, and high-resource translation tasks. Experiments show that our method can significantly improve the translation performance of pre-trained language models.", "comment": " Comments: Work in progress "}, {"arxiv": {"page": "https://arxiv.org/abs/2110.06502", "id": "2110.06502", "pdf": "https://arxiv.org/pdf/2110.06502", "other": "https://arxiv.org/format/2110.06502"}, "title": "Prompt-tuning in ASR systems for efficient domain-adaptation", "author_info": ["Saket Dingliwal", "Ashish Shenoy", "Sravan Bodapati", "Ankur Gandhe", "Ravi Teja Gadde", "Katrin Kirchhoff"], "summary": "Automatic Speech Recognition (ASR) systems have found their use in numerous industrial applications in very diverse domains. Since domain-specific systems perform better than their generic counterparts on in-domain evaluation, the need for memory and compute-efficient domain adaptation is obvious. Particularly, adapting parameter-heavy transformer-based language models used for rescoring ASR hypothesis is challenging. In this work, we overcome the problem using prompt-tuning, a methodology that trains a small number of domain token embedding parameters to prime a transformer-based LM to a particular domain. With just a handful of extra parameters per domain, we achieve much better perplexity scores over the baseline of using an unadapted LM. Despite being parameter-efficient, these improvements are comparable to those of fully-fine-tuned models with hundreds of millions of parameters. We replicate our findings in perplexity numbers to Word Error Rate in a domain-specific ASR system for one such domain.", "comment": " Comments: WeCNLP 2021 camera-ready "}, {"arxiv": {"page": "https://arxiv.org/abs/2110.04525", "id": "2110.04525", "pdf": "https://arxiv.org/pdf/2110.04525", "other": "https://arxiv.org/format/2110.04525"}, "title": "Generating Disentangled Arguments with Prompts: A Simple Event Extraction Framework that Works", "author_info": ["Jinghui Si", "Xutan Peng", "Chen Li", "Haotian Xu", "Jianxin Li"], "summary": "Event Extraction bridges the gap between text and event signals. Based on the assumption of trigger-argument dependency, existing approaches have achieved state-of-the-art performance with expert-designed templates or complicated decoding constraints. In this paper, for the first time we introduce the prompt-based learning strategy to the domain of Event Extraction, which empowers the automatic exploitation of label semantics on both input and output sides. To validate the effectiveness of the proposed generative method, we conduct extensive experiments with 11 diverse baselines. Empirical results show that, in terms of F1 score on Argument Extraction, our simple architecture is stronger than any other generative counterpart and even competitive with algorithms that require template engineering. Regarding the measure of recall, it sets new overall records for both Argument and Trigger Extractions. We hereby recommend this framework to the community, with the code publicly available at https://git.io/GDAP.", "comment": " Comments: Accepted at ICASSP 2022. Without the strict length constraint, this version (slightly) extends the conference camera-ready version "}, {"arxiv": {"page": "https://arxiv.org/abs/2110.01691", "id": "2110.01691", "pdf": "https://arxiv.org/pdf/2110.01691", "other": "https://arxiv.org/format/2110.01691"}, "title": "AI Chains: Transparent and Controllable Human-AI Interaction by Chaining Large Language Model Prompts", "author_info": ["Tongshuang Wu", "Michael Terry", "Carrie J. Cai"], "summary": "Although large language models (LLMs) have demonstrated impressive potential on simple tasks, their breadth of scope, lack of transparency, and insufficient controllability can make them less effective when assisting humans on more complex tasks. In response, we introduce the concept of Chaining LLM steps together, where the output of one step becomes the input for the next, thus aggregating the gains per step. We first define a set of LLM primitive operations useful for Chain construction, then present an interactive system where users can modify these Chains, along with their intermediate results, in a modular way. In a 20-person user study, we found that Chaining not only improved the quality of task outcomes, but also significantly enhanced system transparency, controllability, and sense of collaboration. Additionally, we saw that users developed new ways of interacting with LLMs through Chains: they leveraged sub-tasks to calibrate model expectations, compared and contrasted alternative strategies by observing parallel downstream effects, and debugged unexpected model outputs by \"unit-testing\" sub-components of a Chain. In two case studies, we further explore how LLM Chains may be used in future applications.", "comment": ""}, {"arxiv": {"page": "https://arxiv.org/abs/2109.14330", "id": "2109.14330", "pdf": "https://arxiv.org/pdf/2109.14330", "other": "https://arxiv.org/format/2109.14330"}, "title": "Energy Dependence of Prompt Fission Neutron Multiplicity in the 239Pu(n,f) Reaction", "author_info": ["P. Marini", "J. Taieb", "D. Neudecker", "G. B\u00e9lier", "A. Chatillon", "D. Etasse", "B. Laurent", "P. Morfouace", "B. Morillon", "M. Devlin", "J. A. Gomez", "R. C. Haight", "K. J. Kelly", "J. M. O'Donnell"], "summary": "Accurate multiplicities of prompt fission neutrons emitted in neutron-induced fission on a large energy range are essential for fundamental and applied nuclear physics. Measuring them to high precision for radioactive fissioning nuclides remains, however, an experimental challenge. In this work, the average prompt-neutron multiplicity emitted in the 239Pu(n,f) reaction was extracted as a function of the incident-neutron energy, over the range 1-700~MeV, with a novel technique, which allowed to minimize and correct for the main sources of bias and thus achieve unprecedented precision.", "comment": " Comments: 6 pages, 4 figures "}, {"arxiv": {"page": "https://arxiv.org/abs/2109.13532", "id": "2109.13532", "pdf": "https://arxiv.org/pdf/2109.13532", "other": "https://arxiv.org/format/2109.13532"}, "title": "Template-free Prompt Tuning for Few-shot NER", "author_info": ["Ruotian Ma", "Xin Zhou", "Tao Gui", "Yiding Tan", "Qi Zhang", "Xuanjing Huang"], "summary": "Prompt-based methods have been successfully applied in sentence-level few-shot learning tasks, mostly owing to the sophisticated design of templates and label words. However, when applied to token-level labeling tasks such as NER, it would be time-consuming to enumerate the template queries over all potential entity spans. In this work, we propose a more elegant method to reformulate NER tasks as LM problems without any templates. Specifically, we discard the template construction process while maintaining the word prediction paradigm of pre-training models to predict a class-related pivot word (or label word) at the entity position. Meanwhile, we also explore principled ways to automatically search for appropriate label words that the pre-trained models can easily adapt to. While avoiding complicated template-based process, the proposed LM objective also reduces the gap between different objectives used in pre-training and fine-tuning, thus it can better benefit the few-shot performance. Experimental results demonstrate the effectiveness of the proposed method over bert-tagger and template-based method under few-shot setting. Moreover, the decoding speed of the proposed method is up to 1930.12 times faster than the template-based method.", "comment": " Comments: Work in Progress "}, {"arxiv": {"page": "https://arxiv.org/abs/2109.11797", "id": "2109.11797", "pdf": "https://arxiv.org/pdf/2109.11797", "other": "https://arxiv.org/format/2109.11797"}, "title": "CPT: Colorful Prompt Tuning for Pre-trained Vision-Language Models", "author_info": ["Yuan Yao", "Ao Zhang", "Zhengyan Zhang", "Zhiyuan Liu", "Tat-Seng Chua", "Maosong Sun"], "summary": "Pre-Trained Vision-Language Models (VL-PTMs) have shown promising capabilities in grounding natural language in image data, facilitating a broad variety of cross-modal tasks. However, we note that there exists a significant gap between the objective forms of model pre-training and fine-tuning, resulting in a need for large amounts of labeled data to stimulate the visual grounding capability of VL-PTMs for downstream tasks. To address the challenge, we present Cross-modal Prompt Tuning (CPT, alternatively, Colorful Prompt Tuning), a novel paradigm for tuning VL-PTMs, which reformulates visual grounding into a fill-in-the-blank problem with color-based co-referential markers in image and text, maximally mitigating the gap. In this way, CPT enables strong few-shot and even zero-shot visual grounding capabilities of VL-PTMs. Comprehensive experimental results show that the prompt-tuned VL-PTMs outperform their fine-tuned counterparts by a large margin (e.g., 17.3% absolute accuracy improvement, and 73.8% relative standard deviation reduction on average with one shot in RefCOCO evaluation). All the data and codes will be available to facilitate future research.", "comment": " Comments: Work in progress "}, {"arxiv": {"page": "https://arxiv.org/abs/2109.11212", "id": "2109.11212", "pdf": "https://arxiv.org/pdf/2109.11212", "other": "https://arxiv.org/format/2109.11212"}, "title": "Evolution Patterns of the Peak Energy in the GRB Prompt Emission", "author_info": ["Hao-Xuan Gao", "Jin-Jun Geng", "Yong-Feng Huang"], "summary": "There are two different evolution patterns of the peak energy (Ep) exhibited during the prompt emission phase of gamma-ray bursts (GRBs), i.e., hard-to-soft and intensity-tracking, of which the physical origin remains unknown. Except for low-energy indices of GRB prompt spectra, the evolution patterns of Ep may be another crucial indicator to discriminate radiation mechanisms (e.g., synchrotron or photosphere) for GRBs. We explore the parameter space to find conditions that could generate different evolution patterns of the peak energy in the framework of synchrotron radiation. We have developed a code to calculate the synchrotron emission from a simplified shell numerically, considering three cooling processes (synchrotron, synchrotron self-Compton (SSC), and adiabatic) of electrons, the effect of decaying magnetic field, the effect of the bulk acceleration of the emitting shell, and the effect of a variable source function that describes electrons accelerated in the emitting region. After exploring the parameter space of the GRB synchrotron scenario, we find that the intensity-tracking pattern of Ep could be achieved in two situations. One is that the cooling process of electrons is dominated by adiabatic cooling or SSC+adiabatic cooling at the same time. The other is that the emitting region is under acceleration in addition to the cooling process being dominated by SSC cooling. Otherwise, hard-to-soft patterns of Ep are normally expected. Moreover, a chromatic intensity-tracking pattern of Ep could be induced by the effect of a variable source function.", "comment": " Journal ref:         A&A 656, A134 (2021)       "}, {"arxiv": {"page": "https://arxiv.org/abs/2109.08306", "id": "2109.08306", "pdf": "https://arxiv.org/pdf/2109.08306", "other": "https://arxiv.org/format/2109.08306"}, "title": "SentiPrompt: Sentiment Knowledge Enhanced Prompt-Tuning for Aspect-Based Sentiment Analysis", "author_info": ["Chengxi Li", "Feiyu Gao", "Jiajun Bu", "Lu Xu", "Xiang Chen", "Yu Gu", "Zirui Shao", "Qi Zheng", "Ningyu Zhang", "Yongpan Wang", "Zhi Yu"], "summary": "Aspect-based sentiment analysis (ABSA) is an emerging fine-grained sentiment analysis task that aims to extract aspects, classify corresponding sentiment polarities and find opinions as the causes of sentiment. The latest research tends to solve the ABSA task in a unified way with end-to-end frameworks. Yet, these frameworks get fine-tuned from downstream tasks without any task-adaptive modification. Specifically, they do not use task-related knowledge well or explicitly model relations between aspect and opinion terms, hindering them from better performance. In this paper, we propose SentiPrompt to use sentiment knowledge enhanced prompts to tune the language model in the unified framework. We inject sentiment knowledge regarding aspects, opinions, and polarities into prompt and explicitly model term relations via constructing consistency and polarity judgment templates from the ground truth triplets. Experimental results demonstrate that our approach can outperform strong baselines on Triplet Extraction, Pair Extraction, and Aspect Term Extraction with Sentiment Classification by a notable margin.", "comment": " Comments: 7pages, under blind review "}, {"arxiv": {"page": "https://arxiv.org/abs/2109.07848", "id": "2109.07848", "pdf": "https://arxiv.org/pdf/2109.07848", "other": "https://arxiv.org/format/2109.07848"}, "title": "The Language Model Understood the Prompt was Ambiguous: Probing Syntactic Uncertainty Through Generation", "author_info": ["Laura Aina", "Tal Linzen"], "summary": "Temporary syntactic ambiguities arise when the beginning of a sentence is compatible with multiple syntactic analyses. We inspect to which extent neural language models (LMs) exhibit uncertainty over such analyses when processing temporarily ambiguous inputs, and how that uncertainty is modulated by disambiguating cues. We probe the LM's expectations by generating from it: we use stochastic decoding to derive a set of sentence completions, and estimate the probability that the LM assigns to each interpretation based on the distribution of parses across completions. Unlike scoring-based methods for targeted syntactic evaluation, this technique makes it possible to explore completions that are not hypothesized in advance by the researcher. We apply this method to study the behavior of two LMs (GPT2 and an LSTM) on three types of temporary ambiguity, using materials from human sentence processing experiments. We find that LMs can track multiple analyses simultaneously; the degree of uncertainty varies across constructions and contexts. As a response to disambiguating cues, the LMs often select the correct interpretation, but occasional errors point to potential areas of improvement.", "comment": " Comments: To appear in Proceedings of BlackboxNLP 2021: Analyzing and Interpreting Neural Networks for NLP "}, {"arxiv": {"page": "https://arxiv.org/abs/2109.07830", "id": "2109.07830", "pdf": "https://arxiv.org/pdf/2109.07830", "other": "https://arxiv.org/format/2109.07830"}, "title": "Reframing Instructional Prompts to GPTk's Language", "author_info": ["Swaroop Mishra", "Daniel Khashabi", "Chitta Baral", "Yejin Choi", "Hannaneh Hajishirzi"], "summary": "How can model designers turn task instructions into effective prompts for language models? Backed by extensive empirical analysis on GPT3, we observe important features for successful instructional prompts, and propose several reframing techniques for model designers to create such prompts. For example, a complex task can be decomposed into multiple simpler tasks. We experiment over 12 NLP tasks across 6 diverse categories (question generation, classification, etc.). Our results show that reframing improves few-shot and zero-shot learning performance by 14% and 17% respectively while reducing sample complexity over other recent few-shot baselines. The performance gains are particularly important on large language models, such as GPT3 where tuning models or prompts on large datasets is not feasible. Furthermore, we observe that such gains are not limited to GPT3; the reframed tasks remain superior over raw instructions across different model architectures, underscoring the cross-model generality of these guidelines. We hope these empirical-driven techniques will pave way for more effective ways to prompt LMs in the future.", "comment": " Comments: 11 pages "}, {"arxiv": {"page": "https://arxiv.org/abs/2109.07681", "id": "2109.07681", "pdf": "https://arxiv.org/pdf/2109.07681", "other": "https://arxiv.org/format/2109.07681"}, "title": "The Low-Energy Spectral Index of Gamma-Ray Burst Prompt Emission from Internal Shocks", "author_info": ["Kai Wang", "Zi-Gao Dai"], "summary": "The prompt emission of most gamma-ray bursts (GRBs) typically exhibits a non-thermal Band component. The synchrotron radiation in the popular internal shock model is generally put forward to explain such a non-thermal component. However, the low-energy photon index \u03b1\u223c\u22121.5 predicted by the synchrotron radiation is inconsistent with the observed value \u03b1\u223c\u22121. Here, we investigate the evolution of a magnetic field during propagation of internal shocks within an ultrarelativistic outflow, and revisit the fast cooling of shock-accelerated electrons via synchrotron radiation for this evolutional magnetic field. We find that the magnetic field is first nearly constant and then decays as B\u2032\u221dt\u22121, which leads to a reasonable range of the low-energy photon index, \u22123/2<\u03b1<\u22122/3. In addition, if a rising electron injection rate during a GRB is introduced, we find that \u03b1 reaches \u22122/3 more easily. We thus fit the prompt emission spectra of GRB 080916c and GRB~080825c.", "comment": " Journal ref:         Galaxies 2021, 9(3), 68       "}, {"arxiv": {"page": "https://arxiv.org/abs/2109.07506", "id": "2109.07506", "pdf": "https://arxiv.org/pdf/2109.07506", "other": "https://arxiv.org/format/2109.07506"}, "title": "Dialogue State Tracking with a Language Model using Schema-Driven Prompting", "author_info": ["Chia-Hsuan Lee", "Hao Cheng", "Mari Ostendorf"], "summary": "Task-oriented conversational systems often use dialogue state tracking to represent the user's intentions, which involves filling in values of pre-defined slots. Many approaches have been proposed, often using task-specific architectures with special-purpose classifiers. Recently, good results have been obtained using more general architectures based on pretrained language models. Here, we introduce a new variation of the language modeling approach that uses schema-driven prompting to provide task-aware history encoding that is used for both categorical and non-categorical slots. We further improve performance by augmenting the prompting with schema descriptions, a naturally occurring source of in-domain knowledge. Our purely generative system achieves state-of-the-art performance on MultiWOZ 2.2 and achieves competitive performance on two other benchmarks: MultiWOZ 2.1 and M2M. The data and code will be available at https://github.com/chiahsuan156/DST-as-Prompting.", "comment": " Comments: Accepted to EMNLP 2021 "}, {"arxiv": {"page": "https://arxiv.org/abs/2109.06977", "id": "2109.06977", "pdf": "https://arxiv.org/pdf/2109.06977", "other": "https://arxiv.org/format/2109.06977"}, "title": "Design Guidelines for Prompt Engineering Text-to-Image Generative Models", "author_info": ["Vivian Liu", "Lydia B. Chilton"], "summary": "Text-to-image generative models are a new and powerful way to generate visual artwork. The free-form nature of text as interaction is double-edged; while users have access to an infinite range of generations, they also must engage in brute-force trial and error with the text prompt when the result quality is poor. We conduct a study exploring what prompt components and model parameters can help produce coherent outputs. In particular, we study prompts structured to include subject and style and investigate success and failure modes within these dimensions. Our evaluation of 5493 generations over the course of five experiments spans 49 abstract and concrete subjects as well as 51 abstract and figurative styles. From this evaluation, we present design guidelines that can help people find better outcomes from text-to-image generative models.", "comment": ""}, {"arxiv": {"page": "https://arxiv.org/abs/2109.06513", "id": "2109.06513", "pdf": "https://arxiv.org/pdf/2109.06513", "other": "https://arxiv.org/format/2109.06513"}, "title": "Exploring Prompt-based Few-shot Learning for Grounded Dialog Generation", "author_info": ["Chujie Zheng", "Minlie Huang"], "summary": "Dialog models can be greatly strengthened through grounding on various external information, but grounded dialog corpora are usually not naturally accessible. In this work, we focus on the few-shot learning for grounded dialog generation (GDG). We first propose a simple prompting method for GDG tasks, where different constructs of model input, such as the grounding source and the conversation context, are distinguished through continuous or discrete prompts. On three typical GDG tasks, we empirically demonstrate and analyze in-depth the effectiveness of our method. We then conduct extensive experiments to thoroughly investigate how our prompting method works with different pre-trained models. We show that prompted language models perform superiorly to conversational models, and further analyze various factors that influence the effects of prompting. Overall, our work introduces a prompt-based perspective to the few-shot learning for GDG tasks, and provides valuable findings and insights for future research.", "comment": " Comments: Work in progress "}, {"arxiv": {"page": "https://arxiv.org/abs/2109.04332", "id": "2109.04332", "pdf": "https://arxiv.org/pdf/2109.04332", "other": "https://arxiv.org/format/2109.04332"}, "title": "PPT: Pre-trained Prompt Tuning for Few-shot Learning", "author_info": ["Yuxian Gu", "Xu Han", "Zhiyuan Liu", "Minlie Huang"], "summary": "Prompts for pre-trained language models (PLMs) have shown remarkable performance by bridging the gap between pre-training tasks and various downstream tasks. Among these methods, prompt tuning, which freezes PLMs and only tunes soft prompts, provides an efficient and effective solution for adapting large-scale PLMs to downstream tasks. However, prompt tuning is yet to be fully explored. In our pilot experiments, we find that prompt tuning performs comparably with conventional full-model fine-tuning when downstream data are sufficient, whereas it performs much worse under few-shot learning settings, which may hinder the application of prompt tuning in practice. We attribute this low performance to the manner of initializing soft prompts. Therefore, in this work, we propose to pre-train prompts by adding soft prompts into the pre-training stage to obtain a better initialization. We name this Pre-trained Prompt Tuning framework \"PPT\". To ensure the generalization of PPT, we formulate similar classification tasks into a unified task form and pre-train soft prompts for this unified task. Extensive experiments show that tuning pre-trained prompts for downstream tasks can reach or even outperform full-model fine-tuning under both full-data and few-shot settings. Our approach is effective and efficient for using large-scale PLMs in practice.", "comment": " Comments: 10 pages, 4 figures "}, {"arxiv": {"page": "https://arxiv.org/abs/2109.04144", "id": "2109.04144", "pdf": "https://arxiv.org/pdf/2109.04144", "other": "https://arxiv.org/format/2109.04144"}, "title": "Avoiding Inference Heuristics in Few-shot Prompt-based Finetuning", "author_info": ["Prasetya Ajie Utama", "Nafise Sadat Moosavi", "Victor Sanh", "Iryna Gurevych"], "summary": "Recent prompt-based approaches allow pretrained language models to achieve strong performances on few-shot finetuning by reformulating downstream tasks as a language modeling problem. In this work, we demonstrate that, despite its advantages on low data regimes, finetuned prompt-based models for sentence pair classification tasks still suffer from a common pitfall of adopting inference heuristics based on lexical overlap, e.g., models incorrectly assuming a sentence pair is of the same meaning because they consist of the same set of words. Interestingly, we find that this particular inference heuristic is significantly less present in the zero-shot evaluation of the prompt-based model, indicating how finetuning can be destructive to useful knowledge learned during the pretraining. We then show that adding a regularization that preserves pretraining weights is effective in mitigating this destructive tendency of few-shot finetuning. Our evaluation on three datasets demonstrates promising improvements on the three corresponding challenge datasets used to diagnose the inference heuristics.", "comment": " Comments: Accepted at EMNLP 2021 "}, {"arxiv": {"page": "https://arxiv.org/abs/2109.03685", "id": "2109.03685", "pdf": "https://arxiv.org/pdf/2109.03685", "other": "https://arxiv.org/format/2109.03685"}, "title": "Open Aspect Target Sentiment Classification with Natural Language Prompts", "author_info": ["Ronald Seoh", "Ian Birle", "Mrinal Tak", "Haw-Shiuan Chang", "Brian Pinette", "Alfred Hough"], "summary": "For many business applications, we often seek to analyze sentiments associated with any arbitrary aspects of commercial products, despite having a very limited amount of labels or even without any labels at all. However, existing aspect target sentiment classification (ATSC) models are not trainable if annotated datasets are not available. Even with labeled data, they fall short of reaching satisfactory performance. To address this, we propose simple approaches that better solve ATSC with natural language prompts, enabling the task under zero-shot cases and enhancing supervised settings, especially for few-shot cases. Under the few-shot setting for SemEval 2014 Task 4 laptop domain, our method of reformulating ATSC as an NLI task outperforms supervised SOTA approaches by up to 24.13 accuracy points and 33.14 macro F1 points. Moreover, we demonstrate that our prompts could handle implicitly stated aspects as well: our models reach about 77% accuracy on detecting sentiments for aspect categories (e.g., food), which do not necessarily appear within the text, even though we trained the models only with explicitly mentioned aspect terms (e.g., fajitas) from just 16 reviews - while the accuracy of the no-prompt baseline is only around 65%.", "comment": ""}, {"arxiv": {"page": "https://arxiv.org/abs/2109.03630", "id": "2109.03630", "pdf": "https://arxiv.org/pdf/2109.03630", "other": "https://arxiv.org/format/2109.03630"}, "title": "Discrete and Soft Prompting for Multilingual Models", "author_info": ["Mengjie Zhao", "Hinrich Sch\u00fctze"], "summary": "It has been shown for English that discrete and soft prompting perform strongly in few-shot learning with pretrained language models (PLMs). In this paper, we show that discrete and soft prompting perform better than finetuning in multilingual cases: Crosslingual transfer and in-language training of multilingual natural language inference. For example, with 48 English training examples, finetuning obtains 33.74% accuracy in crosslingual transfer, barely surpassing the majority baseline (33.33%). In contrast, discrete and soft prompting outperform finetuning, achieving 36.43% and 38.79%. We also demonstrate good performance of prompting with training data in multiple languages other than English.", "comment": " Comments: EMNLP 2021 "}, {"arxiv": {"page": "https://arxiv.org/abs/2109.03564", "id": "2109.03564", "pdf": "https://arxiv.org/pdf/2109.03564", "other": "https://arxiv.org/format/2109.03564"}, "title": "NSP-BERT: A Prompt-based Zero-Shot Learner Through an Original Pre-training Task--Next Sentence Prediction", "author_info": ["Yi Sun", "Yu Zheng", "Chao Hao", "Hangping Qiu"], "summary": "Using prompts to utilize language models to perform various downstream tasks, also known as prompt-based learning or prompt-learning, has lately gained significant success in comparison to the pre-train and fine-tune paradigm. Nonetheless, virtually all prompt-based methods are token-level, meaning they all utilize GPT's left-to-right language model or BERT's masked language model to perform cloze-style tasks. In this paper, we attempt to accomplish several NLP tasks in the zero-shot scenario using a BERT original pre-training task abandoned by RoBERTa and other models--Next Sentence Prediction (NSP). Unlike token-level techniques, our sentence-level prompt-based method NSP-BERT does not need to fix the length of the prompt or the position to be predicted, allowing it to handle tasks such as entity linking with ease. Based on the characteristics of NSP-BERT, we offer several quick building templates for various downstream tasks. We suggest a two-stage prompt method for word sense disambiguation tasks in particular. Our strategies for mapping the labels significantly enhance the model's performance on sentence pair tasks. On the FewCLUE benchmark, our NSP-BERT outperforms other zero-shot methods on most of these tasks and comes close to the few-shot methods.", "comment": " Comments: 11 pages, 9 figures "}, {"arxiv": {"page": "https://arxiv.org/abs/2109.02025", "id": "2109.02025", "pdf": "https://arxiv.org/pdf/2109.02025", "other": "https://arxiv.org/format/2109.02025"}, "title": "Revisit prompt J/\u03c8 production in associated with Higgs Boson via gluon fusion at the LHC", "author_info": ["Xue-An Pan", "Zhong-Ming Niu", "Gang Li", "Yu Zhang", "Mao Song", "Jian-You Guo"], "summary": "The production of charmonium associated with Higgs boson via gluon fusion has been investigated in Ref.[Phys.Rev.D66,114002(2002)], in which they considered the contribution of final Higgs boson radiation off the charm quark at tree level and found that this process is to be far too rare to be observable in any of the considered experiments. In this paper, the production of prompt J/\u03c8 associated with Higgs boson via gluon fusion at the 14 TeV LHC within the factorization formalism of NRQCD is revisited. After considering the contribution from the final Higgs boson radiation off the top quark in the loop, which is {more than} three orders of magnitudes over the charm quark at tree level, the production of prompt J/\u03c8 associated with Higgs boson has great potential to be detected. The prompt J/\u03c8 production includes the direct production and indirect production via radiative or hadronic decays of high excited charmonium states. For the direct J/\u03c8+H production via gluon fusion loop-induced, the 3S(8)1 Fock state gives dominant contribution to the cross section, which is about 95\\% to the total direct production. The indirect contribution via loop-induced is appreciable, since the summation of which from \u03c8(2S)+H, \u03c7c1+H and \u03c7c2+H is about 34% to the total cross section of prompt J/\u03c8+H. While the indirect contribution from \u03c7c0+H is tiny, which can be neglected. With the great potential to be detected, prompt J/\u03c8 production in associated with Higgs boson can help us to further understand the mechanism of colour-octet, as well as can be useful to further investigate the coupling of the Higgs boson and fermion.", "comment": " Comments: 11 pages, 5 figures, 4 tables. Accepted by Physical Review D "}, {"arxiv": {"page": "https://arxiv.org/abs/2109.01247", "id": "2109.01247", "pdf": "https://arxiv.org/pdf/2109.01247", "other": "https://arxiv.org/format/2109.01247"}, "title": "Do Prompt-Based Models Really Understand the Meaning of their Prompts?", "author_info": ["Albert Webson", "Ellie Pavlick"], "summary": "Recently, a boom of papers have shown extraordinary progress in few-shot learning with various prompt-based models. Such success can give the impression that prompts help models to learn faster in the same way that humans learn faster when provided with task instructions expressed in natural language. In this study, we experiment with over 30 prompts manually written for natural language inference (NLI). We find that models learn just as fast with many prompts that are intentionally irrelevant or even pathologically misleading as they do with instructively \"good\" prompts. Additionally, we find that model performance is more dependent on the choice of the LM target words (a.k.a. the \"verbalizer\" that converts LM vocabulary prediction to class labels) than on the text of the prompt itself. In sum, we find little evidence that suggests existing prompt-based models truly understand the meaning of their given prompts.", "comment": " Comments: Code available at https://github.com/awebson/prompt_semantics "}, {"arxiv": {"page": "https://arxiv.org/abs/2109.01134", "id": "2109.01134", "pdf": "https://arxiv.org/pdf/2109.01134", "other": "https://arxiv.org/format/2109.01134"}, "title": "Learning to Prompt for Vision-Language Models", "author_info": ["Kaiyang Zhou", "Jingkang Yang", "Chen Change Loy", "Ziwei Liu"], "summary": "Large pre-trained vision-language models like CLIP have shown great potential in learning representations that are transferable across a wide range of downstream tasks. Different from the traditional representation learning that is based mostly on discretized labels, vision-language pre-training aligns images and texts in a common feature space, which allows zero-shot transfer to any downstream task via \\emph{prompting}, i.e., classification weights are synthesized from natural language describing classes of interest. In this work, we show that a major challenge for deploying such models in practice is prompt engineering, which requires domain expertise and is extremely time-consuming -- one needs to spend a significant amount of time on words tuning since a slight change in wording could have a huge impact on performance. Inspired by recent advances in prompt learning research in natural language processing (NLP), we propose \\emph{Context Optimization (CoOp)}, a simple approach specifically for adapting CLIP-like vision-language models for downstream image recognition. Concretely, CoOp models a prompt's context words with learnable vectors while the entire pre-trained parameters are kept fixed. To handle different image recognition tasks, we provide two implementations of CoOp: unified context and class-specific context. Through extensive experiments on 11 datasets, we demonstrate that CoOp requires as few as one or two shots to beat hand-crafted prompts with a decent margin and is able to gain significant improvements when using more shots, e.g., with 16 shots the average gain is around 15\\% (with the highest reaching over 45\\%). Despite being a learning-based approach, CoOp achieves superb domain generalization performance compared with the zero-shot model using hand-crafted prompts.", "comment": " Comments: Code: https://github.com/KaiyangZhou/CoOp "}, {"arxiv": {"page": "https://arxiv.org/abs/2109.00720", "id": "2109.00720", "pdf": "https://arxiv.org/pdf/2109.00720", "other": "https://arxiv.org/format/2109.00720"}, "title": "LightNER: A Lightweight Generative Framework with Prompt-guided Attention for Low-resource NER", "author_info": ["Xiang Chen", "Ningyu Zhang", "Lei Li", "Xin Xie", "Shumin Deng", "Chuanqi Tan", "Fei Huang", "Luo Si", "Huajun Chen"], "summary": "Most existing NER methods rely on extensive labeled data for model training, which struggles in the low-resource scenarios with limited training data. Recently, prompt-tuning methods for pre-trained language models have achieved remarkable performance in few-shot learning by exploiting prompts as task guidance to reduce the gap between training progress and downstream tuning. Inspired by prompt learning, we propose a novel lightweight generative framework with prompt-guided attention for low-resource NER (LightNER). Specifically, we construct the semantic-aware answer space of entity categories for prompt learning to generate the entity span sequence and entity categories without any label-specific classifiers. We further propose prompt-guided attention by incorporating continuous prompts into the self-attention layer to re-modulate the attention and adapt pre-trained weights. Note that we only tune those continuous prompts with the whole parameter of the pre-trained language model fixed, thus, making our approach lightweight and flexible for low-resource scenarios and can better transfer knowledge across domains. Experimental results show that LightNER can obtain comparable performance in the standard supervised setting and outperform strong baselines in low-resource settings by tuning only a small part of the parameters.", "comment": " Comments: Work in progress "}, {"arxiv": {"page": "https://arxiv.org/abs/2108.13161", "id": "2108.13161", "pdf": "https://arxiv.org/pdf/2108.13161", "other": "https://arxiv.org/format/2108.13161"}, "title": "Differentiable Prompt Makes Pre-trained Language Models Better Few-shot Learners", "author_info": ["Ningyu Zhang", "Luoqiu Li", "Xiang Chen", "Shumin Deng", "Zhen Bi", "Chuanqi Tan", "Fei Huang", "Huajun Chen"], "summary": "Large-scale pre-trained language models have contributed significantly to natural language processing by demonstrating remarkable abilities as few-shot learners. However, their effectiveness depends mainly on scaling the model parameters and prompt design, hindering their implementation in most real-world applications. This study proposes a novel pluggable, extensible, and efficient approach named DifferentiAble pRompT (DART), which can convert small language models into better few-shot learners without any prompt engineering. The main principle behind this approach involves reformulating potential natural language processing tasks into the task of a pre-trained language model and differentially optimizing the prompt template as well as the target label with backpropagation. Furthermore, the proposed approach can be: (i) Plugged to any pre-trained language models; (ii) Extended to widespread classification tasks. A comprehensive evaluation of standard NLP tasks demonstrates that the proposed approach achieves a better few-shot performance. Code is available in https://github.com/zjunlp/DART.", "comment": " Comments: Accepted by ICLR 2022 "}, {"arxiv": {"page": "https://arxiv.org/abs/2108.13115", "id": "2108.13115", "pdf": "https://arxiv.org/pdf/2108.13115", "other": "https://arxiv.org/format/2108.13115"}, "title": "Measurement of the nuclear modification factor and prompt charged particle production in pPb and pp collisions at sNN\u2212\u2212\u2212\u221a=5TeV", "author_info": [" LHCb collaboration", "R. Aaij", "C. Abell\u00e1n Beteta", "T. Ackernley", "B. Adeva", "M. Adinolfi", "H. Afsharnia", "C. A. Aidala", "S. Aiola", "Z. Ajaltouni", "S. Akar", "J. Albrecht", "F. Alessio", "M. Alexander", "A. Alfonso Albero", "Z. Aliouche", "G. Alkhazov", "P. Alvarez Cartelle", "S. Amato", "J. L. Amey", "Y. Amhis", "L. An", "L. Anderlini", "A. Andreianov", "M. Andreotti"], "summary": "The production of prompt charged particles in proton-lead collisions and in proton-proton collisions at the nucleon-nucleon centre-of-mass energy sNN\u2212\u2212\u2212\u221a=5TeV is studied at LHCb as a function of pseudorapidity (\u03b7) and transverse momentum (pT) with respect to the proton beam direction. The nuclear modification factor for charged particles is determined as a function of \u03b7 between \u22124.8<\u03b7<\u22122.5 (backward region) and 2.0<\u03b7<4.8 (forward region), and pT between 0.2<pT<8.0GeV/c. The results show a suppression of charged particle production in proton-lead collisions relative to proton-proton collisions in the forward region and an enhancement in the backward region for pT larger than 1.5GeV/c. This measurement constrains nuclear PDFs and saturation models at previously unexplored values of the parton momentum fraction down to 10\u22126.", "comment": " Report number:           LHCb-PAPER-2021-015, CERN-EP-2021-130                                    "}]}